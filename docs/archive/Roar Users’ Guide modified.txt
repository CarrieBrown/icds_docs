<!DOCTYPE html>
<html lang="en">
<head>
<title>Roar Supercomputer Users’ Guide | PSU Institute for Computational and Data Sciences | High Performance Computing at Penn State</title>
		</head>

<body >


<!-- CONTENT WRAP -->

<div role="main" id="main" class="color-based-header section-gold clear">
  <div class="container article-header max-width">
    <div class="column full max-width flex-vertical-bottom"></div>
        <div class="headline-positioner"><a href="https://www.icds.psu.edu/computing-services/" class="breadcrumb">Computing Services</a>      <h1><span>Roar Supercomputer Users’ Guide</span></h1>
    </div>
    <!-- end .headline-positioner -->
  </div>
  <!-- end .container article-header max-width -->
  <div class="container align-flex-start columns-margined max-width container-article">
    <div class="column padding-lr three-quarters" id="userguide">
            
      	
	<a name="0-were-redesigning-the-roar-user-guide"></a><br>
	<h3>0 We&#8217;re Redesigning the Roar User Guide!</h3>
	<p>We&#8217;re currently working to revise the Roar User Guide with updated content in an easier to use format, and we&#8217;d like your input!</p>
<p>All Roar users- students, faculty, and staff- are invited to take a brief, five minute survey to help us</p>
<p><a href="https://pennstate.qualtrics.com/jfe/form/SV_7TBk5Pdt2rKiwTP">Click here to take our Roar User Guide survey.</a></p>




	<a name="01-00-introduction"></a><br>
	<h3>1 Introduction</h3>
	<p><!--l. 78--></p>
<p class="noindent">Computational and data sciences are a fast growing mode of discovery, in addition to traditional theory and experiment, because they provides a unique virtual laboratory to investigate complex problems that are otherwise impossible or impractical to address. Such problems can range from understanding the physics of the origins of the universe, the genomic/molecular basis of disease, or the socioeconomic impacts of a digital society; to designing smart structures and nanoscale tailored materials; or to developing systems for clean energy or realtime responses to threats. The intellectual strength of computational science lies with its universality &#8211; all research domains benefit from it. The expectation is that The Institute for Computational and Data Sciences will succeed both in facilitating research across a broad spectrum of disciplines and in securing significant external resources for cyberscience-related research for years to come.<br />
<!--l. 80--></p>
<p><!--l. 94--></p>




	<a name="01-01-icds-aci"></a><br>
	<h4>1.1 What is Roar?</h4>
	<p class="noindent">The Roar supercomputer (formerly known as the Institute for Computational and Data Sciences Advanced CyberInfrastructure, or ICDS-ACI) is our high-performance computing (HPC) infrastructure. The name also refers to the services associated with this system. Roar provides secure, high-quality advanced computing and storage resources to the Penn State research community.</p>




	<a name="01-02-icds-aci"></a><br>
	<h4>1.2 What does Roar do?</h4>
	<p><!--l. 84--></p>
<p class="noindent">Roar contributes to the ICDS mission by providing researchers with the hardware, software, and technical expertise needed to solve problems of scientific and societal importance. Roar provides a variety of services, including operations, backup, technical consulting, and training. It offers over 1000 servers with more than 23,000 processing cores, 6 Petabytes (PB) of disk parallel file storage, 12 PB of tape archive storage, high-speed Ethernet and Infiniband interconnects, and a large software stack. Roar is also compliant with specific NIH and NIST security controls.</p>




	<a name="01-03-mission"></a><br>
	<h4>1.3 Our Mission</h4>
	<p><!--l. 87--></p>
<p class="noindent">The mission of the Institute for Computational and Data Sciences is to build capacity to solve problems of scientific and societal importance through cyber-enabled research. As computation and data science become increasingly vital modes of inquiry, we enable researchers to develop innovative computational methods and to apply those methods to research challenges. Specifically, we:</p>
<ul class="itemize1">
<li class="itemize">foster a collaborative, interdisciplinary scholarly community focused on the development and application of innovative computational methods;</li>
<li class="itemize">expand participation in interdisciplinary research through strategic investments and effective outreach;<br />
and</li>
<li class="itemize">provide a vibrant world-class cyberinfrastructure by maintaining and continually improving hardware and software solutions and technical expertise.</li>
</ul>




	<a name="01-04-vision"></a><br>
	<h4>1.4 Our Vision</h4>
	<p><!--l. 95--></p>
<p class="noindent">ICDS will expand its role as an international leader in advancing cyberinfrastructure along with computational and data-driven methods and in driving their application to interdisciplinary research. We will use our expertise coupled with our state-of-the-science research infrastructure to support cyber-enabled interdisciplinary collaborations and attract the worlds best researchers. These researchers will form a vibrant intellectual community empowered to use the latest and most effective computational methods to make transformative discoveries for science and society.</p>




	<a name="02-00-ics-aci-history"></a><br>
	<h3>2 Roar History</h3>
	<p class="noindent">In 2011 Penn State established an intra-university Cyberscience Task-Force to develop a strategic and coherent vision for cyberscience at the university. On the recommendations of this task-force, the Institute for CyberScience was established in 2012. ICDS is one of seven interdisciplinary research institutes under the Office of the Senior Vice President for Research. Peer institutes include the Huck Institutes of the Life Sciences, the Materials Research Institute, the Institutes of Energy and the Environment, the Social Science Research Institute, the Cancer Research Institute, and the Clinical and Translational Science Institute.<br />
<!--l. 101--></p>
<p class="indent">Under its first director, Padma Raghavan, the institute began a cluster hiring initiative in 2012-2013, in partnership with Penn State colleges and institutes. This initiative, the <a href="https://www.icds.psu.edu/about/icds-co-hires/">ICDS Co-hire program</a>, brought in promising computational experts from a range of fields.<br />
<!--l. 103--></p>
<p class="indent">In 2014 Executive Vice President and Provost Nick Jones and Vice President for Research Neil Sharkey initiated a series of steps designed to help Penn State deliver the broad spectrum of computing and data services that are required to advance research. As part of this ongoing process, ICDS continues to develop and sustain advanced cyberinfrastructure, with the goal of accelerating research outcomes by enhancing researcher productivity. In 2019, the institute was renamed to be the Institute for Computational and Data Sciences. In 2020, the supercomputer (formerly named the Institute for Computational and Data Sciences Advanced Cyber Infrastructure, or ICDS-ACI) was renamed Roar.</p>




	<a name="03-00-system-overview"></a><br>
	<h3>3 System Overview</h3>
	<p class="noindent">Roar is a heterogeneous cluster that consists of multiple node-types connected to a common file system. The primary portions are ACI-b, the batch portion of the cluster; ACI-i, the interactive portion; and the data-manager nodes.</p>




	<a name="03-01-aci-b"></a><br>
	<h4>3.1 ACI-b</h4>
	<p><!--l. 111--></p>
<p class="noindent">ACI-b, the batch portion of Roar, is used to submit jobs to dedicated resources. ACI-b has the hostname</p>
<pre>submit.aci.ics.psu.edu</pre>
<p><!--l. 114--></p>
<p class="noindent">and can be logged into using <code>ssh</code>. Users will be placed on a head node, which is not intended for heavy processing. The head node should only be used to submit jobs.<br />
<!--l. 117--></p>
<p class="noindent">Typically, a job submission script including the resource requests and the commands is submitted. A job scheduler will wait until dedicated resources are available for this job. Jobs are submitted either to the Open Queue allocation, which any Penn State student/faculty/staff are able to use, or to a paid allocation. Jobs are typically submitted with the qsub command:</p>
<pre>qsub subScript.pbs</pre>
<p><!--l. 120--></p>
<p class="noindent"><!--l. 124--></p>
<h5 class="subsubsectionHead"><span class="titlemark">3.1.1 </span> <a id="x1-90003.1.1"></a>Types of ACI-b Nodes</h5>
<p><!--l. 126--></p>
<p class="noindent">Compute resources are available in four configurations: Basic Memory, Standard Memory, High Memory, and GPU.</p>

<table id="tablepress-4" class="tablepress tablepress-id-4">
<thead>
<tr class="row-1 odd">
	<th class="column-1">Node Types</th><th class="column-2">Specifications</th>
</tr>
</thead>
<tbody class="row-hover">
<tr class="row-2 even">
	<td class="column-1">Basic</td><td class="column-2">2.2 GHz Intel Xeon Processor, 24 CPU/server, 128 GB RAM, 40 Gbps Ethernet</td>
</tr>
<tr class="row-3 odd">
	<td class="column-1">Standard</td><td class="column-2">2.8 GHz Intel Xeon Processor, 20 CPU/server, 256 GB RAM, FDR Infiniband, 40 Gbps Ethernet</td>
</tr>
<tr class="row-4 even">
	<td class="column-1">High</td><td class="column-2">2.2 GHz Intel Xeon Processor, 40 CPU/server, 1 TB RAM, FDR Infiniband, 10 Gbps Ethernet</td>
</tr>
<tr class="row-5 odd">
	<td class="column-1">GPU</td><td class="column-2">2.5 GHz Intel Xeon Processor, 2 Nvidia Tesla K80 computing modules/server, 24 CPU/server, Double Precision, FDR Infiniband, 10 Gbps Ethernet</td>
</tr>
</tbody>
</table>
<!-- #tablepress-4 from cache -->
<div class="tabular"></div>
<p><!--l. 139--></p>




	<a name="03-02-aci"></a><br>
	<h4>3.2 ACI-I</h4>
	<p class="noindent">ACI-i provides a set of interactive cores that are configured as common GUI interactive systems. ACI-i is a shared resource where users are placed on an interactive node with other users.<br />
<!--l. 147--></p>
<p>ACI-i may only be <a href="https://www.icds.psu.edu/userguide/05-00-basics-aci-resources/05-04-connecting-aci/05-041-open-ondemand/">accessed via Open OnDemand</a>.</p>
<p class="indent">Often ACI-i is used to develop and test small scale test cases due to the ability to use a graphical user interface. Once the model has been developed, it can be submitted as a job to ACI-b to take advantage of the greater computational resources available on ACI-b.<br />
<!--l. 150--></p>
<p class="indent">For example, a researcher might log in to ACI-i to develop a finite element model using the graphical user interface for COMSOL. To test the model, small simulations on a course mesh can be run on ACI-i. Then once the model has been deemed satisfactory, the researcher can log in to ACI-b to submit the COMSOL model using a much finer mesh.<br />
<!--l. 152--></p>
<p class="indent">Individual processes are limited to</p>
<ul class="itemize1">
<li class="itemize">4 processors</li>
<li class="itemize">12 CPU hours per process</li>
<li class="itemize">48 GB resident memory</li>
</ul>
<p><!--l. 158--></p>
<p class="noindent">on ACI-i. Note that the resident memory constraint still allows for memory that can be sent to virtual memory during times of high usage.<br />
<!--l. 160--></p>




	<a name="03-03-aci-open-queue"></a><br>
	<h4>3.3 Roar Open Queue</h4>
	<p><!--l. 162--></p>
<p class="noindent">All Penn State students, faculty and staff are able to run on the Roar &#8220;open queue&#8221; on ACI-b for no charge. The current limits per user on the open queue are:</p>
<ul>
<li class="noindent"><span class="normaltextrun"><span lang="">100 jobs pending</span></span></li>
<li class="noindent"><span class="normaltextrun"><span lang="">100 cores executing jobs at any given time</span></span></li>
<li class="noindent"><span class="normaltextrun"><span lang="">48-hour job wall-times</span></span></li>
<li class="noindent"><span class="normaltextrun"><span lang="">24-hour interactive session durations</span></span><span class="eop"><span lang=""> </span></span></li>
</ul>
<p class="noindent">Jobs requiring more time or processors than this are required to run on an allocation.<br />
<!--l. 164--></p>
<p class="indent">Jobs running on the open allocation are placed on available compute nodes. These are available as they are not being used by the group who has an allocation reservation on that node. If that group does require these resources, the running open queue jobs are pre-empted. Once the allocation job has completed, your job will continue, if the code running allows for this to occur.<br />
<!--l. 166--></p>
<p class="indent">ACI-i is open to any and all users, regardless of allocation.<br />
<!--l. 168--></p>




	<a name="03-04-hprc"></a><br>
	<h4>3.4 HPRC</h4>
	<p>HPRC is the hybrid-cloud portion of Roar, utilizing virtual cores at a lower cost. HPRC jobs are submitted from ACI-b head nodes, with the host name</p>
<pre>submit.aci.ics.psu.edu</pre>
<p>…and can be logged into using ssh.</p>
<p>Users will be placed on a head node, which is not intended for heavy processing. The head node should only be used to submit jobs.</p>
<p>Typically, a job submission script including the resource requests and the commands is submitted. A job scheduler will wait until dedicated resources are available for this job. Jobs are typically submitted with the qsub command:</p>
<pre>qsub subScript.pbs</pre>




	<a name="03-05-filesystems"></a><br>
	<h4>3.5 Filesystems</h4>
	<p class="noindent">The Roar system has several filesystems available for users for active and archival storage. Active storage can be utilized by running jobs and archival storage is intended for long-term data storage.<br />
<!--l. 173--></p>
<p class="indent"><strong>Active Storage</strong><br />
All of the active storage is available from all of the Roar systems. Individual users have home, work and scratch directories that are created during account creation. The work and scratch directories should have links within the home directory, allowing for easy use. A user’s home directory is for personal files and cannot be shared. Work and scratch are able to be shared. Both home and work are backed up. Scratch is not backed up and files are subject to deletion 30 days after creation. <em>Do not keep important files on scratch.</em></p>
<p><!--l. 176--></p>
<p class="indent">Group directories can be created to help facilitate research within a group and can be purchased as an allocation. Note that individual allocations will have separate locations within the group directory.<br />
<!--l. 178--></p>
<p class="indent"><strong>Archival storage</strong><br />
The archival storage is only available on the <a href="#03-05-data-manager">Data Manager</a> nodes. Archival storage can be purchased as an allocation.</p>
<p>By design, archival storage is best suited for storing relatively small numbers of large files that will be accessed infrequently. Compared to active storage, read and write performance in archive storage will be very slow. Attempting to utilize archive storage when active storage would be more appropriate can result in system degradations that negatively impact all users of our shared system. Limiting files to a minimum 1GB or 1000 per TB is a good rule of thumb.</p>

<table id="tablepress-5" class="tablepress tablepress-id-5">
<thead>
<tr class="row-1 odd">
	<th class="column-1">Space</th><th class="column-2">Location</th><th class="column-3">Quota</th><th class="column-4">File Limit</th><th class="column-5">Backed-Up</th><th class="column-6">File Lifetime Limit</th>
</tr>
</thead>
<tbody class="row-hover">
<tr class="row-2 even">
	<td class="column-1">Home</td><td class="column-2">/storage/home/userID</td><td class="column-3">10 GB</td><td class="column-4">500,000</td><td class="column-5">Yes</td><td class="column-6">None</td>
</tr>
<tr class="row-3 odd">
	<td class="column-1">Work</td><td class="column-2">/storage/work/userID</td><td class="column-3">128 GB</td><td class="column-4">1,000,000</td><td class="column-5">Yes</td><td class="column-6">None</td>
</tr>
<tr class="row-4 even">
	<td class="column-1">Scratch</td><td class="column-2">/gpfs/scratch/userID</td><td class="column-3">None</td><td class="column-4">1,000,000</td><td class="column-5">No</td><td class="column-6">30 Days</td>
</tr>
<tr class="row-5 odd">
	<td class="column-1">Group</td><td class="column-2">/gpfs/group/groupID</td><td class="column-3">5 TB blocks</td><td class="column-4">1,000,000 per TB</td><td class="column-5">Yes</td><td class="column-6">None</td>
</tr>
<tr class="row-6 even">
	<td class="column-1">Archive</td><td class="column-2">/archive/groupID</td><td class="column-3">5 TB blocks</td><td class="column-4">Suggested lower limit of 1G/file or 1,000/TB</td><td class="column-5">No</td><td class="column-6">None</td>
</tr>
</tbody>
</table>
<!-- #tablepress-5 from cache -->
<div class="tabular">
<p><!--l. 194--></p>
</div>




	<a name="03-06-data-manager"></a><br>
	<h4>3.6 Data Manager</h4>
	<p class="noindent">The data manager nodes are dedicated to file transfers, both within Roar and between Roar and other systems. For active storage, it can be used with command line file-transfer tools, such as <code>rsync</code>, <code>sftp</code> or <code>scp</code>, as well as with Globus, WinSCP, or FileZilla.<br />
<!--l. 198--></p>
<p class="indent">The data manager hostname is</p>
<pre>datamgr.aci.ics.psu.edu</pre>
<p><!--l. 201--></p>
<p class="nopar"><!--l. 203--></p>
<p class="indent">For example, to connect to data manager, you can use the command</p>
<pre>ssh datamgr.aci.ics.psu.edu</pre>
<p>to log in. After logging in, you can perform your file transfer.</p>
<p><strong>Important:</strong> Do not use tools that attempt to mirror or replicate directory and file trees (such as rsync) into archive storage. Using such tools with archive storage can result in system degradations that negatively impact all users of our shared system.</p>
<p><!--l. 206--></p>




	<a name="04-00-system-access"></a><br>
	<h3>4 System Access</h3>
	<p class="noindent">The Roar systems are available for all users with Penn State access. Non-Penn State members who are collaborating with Penn State researchers are able to get a Penn State SLIM access account and then sign up for a Roar account.</p>




	<a name="04-01-sponsorship"></a><br>
	<h4>4.1 Sponsorship</h4>
	<p><!--l. 213--></p>
<p class="noindent">Each non-faculty member signing up for an account must have a sponsor. This is typically the adviser or course instructor. The request requires the Penn State username and not an alias. The <a href="http://www.work.psu.edu/ldap/">Penn State directory</a> can be used to figure out the username if only another email alias is known.<br />
<!--l. 215--></p>




	<a name="04-02-permissions-use-resources"></a><br>
	<h4>4.2 Permissions to use Resources</h4>
	<p><!--l. 217--></p>
<p class="noindent">The users who have access to an allocation are placed in an allocation group. Users can see all of the groups they are in by using the <code>id</code> command.</p>
<p><!--l. 220--></p>
<p class="nopar"><!--l. 222--></p>
<p class="indent">To gain access to an allocation or a group storage, have the PI send an email to the i-ASK Center (<a href="mailto:iask@ics.psu.edu">iask@ics.psu.edu</a>) stating the user IDs (ex. abc123) and the allocation(s) and group storage(s) you wish to add them to. This explicit permission must be granted before users are allowed access.<br />
<!--l. 224--></p>




	<a name="04-03-getting-account"></a><br>
	<h4>4.3 Getting an Account</h4>
	<p><!--l. 227--></p>
<p class="noindent">Users with a Penn State ID can sign up for an account using: <a class="url" href="https://accounts.aci.ics.psu.edu"><span class="cmtt-10">https://accounts.aci.ics.psu.edu</span></a><br />
<!--l. 229--></p>
<p class="indent">Faculty member accounts require no sponsorship. Students and staff require a faculty sponsor, which must be listed by their original Penn State ID, rather than by an alias. The sponsor will get an email stating they were listed as a sponsor. The faculty member can respond to the iAsk center (<a class="url" href="mailto:iAsk@ics.psu.edu"><span class="cmtt-10">iAsk@ics.psu.edu</span></a>) with either explicit approval or a denial. If no denial is given, the student or staff member will be granted implicit approval after two business days. Faculty members can send an email with multiple users if they will be sponsoring multiple accounts, such as for a class project. After an account has been approved, it can take up to twenty-four hours before the system updates and the user is able to login.<br />
<!--l. 232--></p>
<p class="indent">Users who do not have Penn State ID but are collaborators from other institutions need to acquire a Penn State SLIM account before they sign up for a Roar account and Duo. To request SLIM account, please follow these <a href="https://www.icds.psu.edu/computing-services/account-setup/">instructions</a>.<br />
<!--l. 235--></p>
<p class="indent">You will need to wait for your SLIM access account to be created before you can proceed to request your Roar account or sign up for two-factor authentication.</p>




	<a name="05-00-basics-aci-resources"></a><br>
	<h3>5 Basics of the Roar Resources</h3>
	



	<a name="05-01-system-usage"></a><br>
	<h4>5.1 System Usage</h4>
	<p><!--l. 242--></p>
<p class="noindent">The Roar system uses the Red Hat 7.9 Linux operating system with the module system set up for software. All users will have to use the terminal to access programs, including Open OnDemand users of ACI-i.</p>
<p><!--l. 244--></p>
<h5 class="subsubsectionHead"><span class="titlemark">5.1.1 </span> <a id="x1-210005.1.1"></a>Shells</h5>
<p><!--l. 245--></p>
<p class="noindent">Unix/Linux shells are command line interpreters that allow for a user to interact with their operating system through utility commands and programs. The Default Unix/Linux shell is BASH (the Bourne-Again SHell) which has extensive online documentation, and common or necessary commands are shown in the table below.</p>

<table id="tablepress-6" class="tablepress tablepress-id-6">
<thead>
<tr class="row-1 odd">
	<th class="column-1">Command</th><th class="column-2">Description (For full documentation, use the command 'man command' to bring up the manual or find online documentation)</th>
</tr>
</thead>
<tbody class="row-hover">
<tr class="row-2 even">
	<td class="column-1">ls</td><td class="column-2">The 'list' (ls) command is used to display all the files in your current directory. Using the '-a' flag will also show any hidden files (typically files beginning with a '.' like .bashrc)</td>
</tr>
<tr class="row-3 odd">
	<td class="column-1">cd</td><td class="column-2">This is the 'change directory' command. Use this to traverse directories (like 'cd work'). To move back a directory level, use 'cd..'.</td>
</tr>
<tr class="row-4 even">
	<td class="column-1">mv</td><td class="column-2">The 'move' command takes two arguments, the first being the file to move and the second being the directory said file should be moved to ('mv file.txt /work/newdirectory/'). Note: 'mv' can also be used to rename a file if the second argument is simply a new file name instead of a directory.</td>
</tr>
<tr class="row-5 odd">
	<td class="column-1">mkdir</td><td class="column-2">This command is used to make directories.</td>
</tr>
<tr class="row-6 even">
	<td class="column-1">rmdir</td><td class="column-2">This command is used to delete directories ('rm -rf directory' would also work).</td>
</tr>
<tr class="row-7 odd">
	<td class="column-1">touch</td><td class="column-2">This command is used to create files in a similar way to mkdir. ('touch test.txt' will create an empty text file named test).</td>
</tr>
<tr class="row-8 even">
	<td class="column-1">rm</td><td class="column-2">This is the 'remove' command. As mentioned above, it can be used recursively to delete entire directory trees, or it can be used with no flags and a file as the argument to delete a single file.</td>
</tr>
<tr class="row-9 odd">
	<td class="column-1">locate</td><td class="column-2">This command is used to locate files on a system. The flag '-i' will make the query case-<br />
insensitive, and asterisks ('*') will indicate wildcard characters.</td>
</tr>
<tr class="row-10 even">
	<td class="column-1">clear</td><td class="column-2">Clears the terminal of all previous outputs leaving you with a clean prompt.</td>
</tr>
<tr class="row-11 odd">
	<td class="column-1">history</td><td class="column-2">Shows the previous commands entered.</td>
</tr>
<tr class="row-12 even">
	<td class="column-1">find</td><td class="column-2">Used for finding files, typically with the -name flag and the name of the file.</td>
</tr>
<tr class="row-13 odd">
	<td class="column-1">grep</td><td class="column-2">Used for searching within files.</td>
</tr>
<tr class="row-14 even">
	<td class="column-1">awk</td><td class="column-2">A programming language typically used for data extraction.</td>
</tr>
<tr class="row-15 odd">
	<td class="column-1">id</td><td class="column-2">Show all of the groups a user is in.</td>
</tr>
<tr class="row-16 even">
	<td class="column-1">du</td><td class="column-2">Show the disk usage. Typically used with -h (for human readable) and –max-depth=1 to limit to only the directories in that level rather than all files.</td>
</tr>
<tr class="row-17 odd">
	<td class="column-1">env</td><td class="column-2">Print out all of the current environment variables.</td>
</tr>
<tr class="row-18 even">
	<td class="column-1">less</td><td class="column-2">View a file.</td>
</tr>
<tr class="row-19 odd">
	<td class="column-1">cp</td><td class="column-2">Copy a file. Note the -r (recursive) flag can be used to copy directories.</td>
</tr>
<tr class="row-20 even">
	<td class="column-1">alias</td><td class="column-2">Create an alias (something short) that is interpreted as something else (a complicated command).</td>
</tr>
<tr class="row-21 odd">
	<td class="column-1">pwd</td><td class="column-2">Print the current working directory.</td>
</tr>
<tr class="row-22 even">
	<td class="column-1">chmod</td><td class="column-2">Change file permissions.</td>
</tr>
<tr class="row-23 odd">
	<td class="column-1">chgrp</td><td class="column-2">Change group for a file or directory.</td>
</tr>
<tr class="row-24 even">
	<td class="column-1">ldd</td><td class="column-2">Show the shared libraries required for an executable or library.</td>
</tr>
<tr class="row-25 odd">
	<td class="column-1">top</td><td class="column-2">See the node usage.  Often used with command U <username> .</td>
</tr>
<tr class="row-26 even">
	<td class="column-1">/usr/bin/time</td><td class="column-2">Show time and memory statistics for a command being run.  Often used with the -v (verbose) flag.</td>
</tr>
<tr class="row-27 odd">
	<td class="column-1">bg</td><td class="column-2">Continue running a paused task in the background</td>
</tr>
<tr class="row-28 even">
	<td class="column-1">fg</td><td class="column-2">Bring a background task into the foreground</td>
</tr>
<tr class="row-29 odd">
	<td class="column-1">Ctrl + c</td><td class="column-2">Kill a process.</td>
</tr>
<tr class="row-30 even">
	<td class="column-1">Ctrl + z</td><td class="column-2">Suspend a process</td>
</tr>
<tr class="row-31 odd">
	<td class="column-1">Ctrl + r </td><td class="column-2">Search through your history for a command that includes the text typed next.  </td>
</tr>
</tbody>
</table>
<!-- #tablepress-6 from cache -->
<div class="tabular">
<table id="TBL-4" class="tabular" rules="groups" cellspacing="0" cellpadding="0">
<colgroup id="TBL-4-1g">
<col id="TBL-4-1" /></colgroup>
<colgroup id="TBL-4-2g">
<col id="TBL-4-2" /></colgroup>
<tbody>
<tr class="hline">
<td>
<hr />
</td>
<td>
<hr />
</td>
</tr>
</tbody>
</table>
</div>
<p><!--l. 281--></p>
<p class="indent">There are also some special characters to be aware of that will be helpful.</p>
<ul class="itemize1">
<li class="itemize"><code>~</code> is your home directory</li>
<li class="itemize"><code>.</code> means here</li>
<li class="itemize"><code>..</code> means up one directory</li>
<li class="itemize"><code>*</code> is the wildcard: <code>*</code> for all files or <code>*.png</code> for all png files</li>
<li class="itemize"><code>|</code>is pipe (send the output to another command)</li>
<li class="itemize"><code>&gt;</code> means write command output to a file (Example: <code>ls &gt; log.ls</code>)</li>
</ul>
<p><!--l. 291--></p>
<p class="indent">Most commands have a manual that show all of the different ways the command can be used. For example,</p>
<pre>man ls</pre>
<p><!--l. 294--></p>
<p class="nopar">shows all of the info for the <code>ls</code> command. You can use the arrows to scroll through the manual and the letter <code>q</code> for quit. Some commands will also provide a shortened version of the manual showing the available flags if an incorrect flag is used. For example,</p>
<pre>mam-list-funds -banana</pre>
<p><!--l. 298--></p>
<p class="nopar">brings up a list of all of the flags available for <code>mam-list-funds</code>. Any non-working flag will allow for this. Note that this doesn’t give information about what the flags do, just what the flags are. This may be enough to remind you of something you had done previously.<br />
<!--l. 302--></p>
<p class="indent">All shells utilize configuration files. For BASH, this is split between 2 files: <code>~/.bash_profile</code> and <code>~/.bashrc</code>.<br />
(NOTE: <code>~/</code> in Linux is a way to specify your own home directory!). The <code>.bash_profile</code> file is always parsed when a terminal is open, including with an SSH session. To connect the two in such a way that <code>.bashrc</code> will always be sourced for a session, make sure this code is included in your <code>~/.bash_profile</code>:</p>
<pre>if [ -f ~/.bashrc ]; then . ~/.bashrc fi</pre>
<p><!--l. 305--></p>
<p class="nopar"><!--l. 307--></p>
<h5 class="subsubsectionHead"><span class="titlemark">5.1.2 </span> <a id="x1-220005.1.2"></a>Alternative Shells</h5>
<p><!--l. 309--></p>
<p class="noindent">BASH is only the default shell, and it doesn’t come with quite a few features that many Linux power-users would like to have on the command-line. Other common shells include KSH (KornSHell), ZSH (Z SHell), and FISH (Friendly-Interface SHell). These shells all have documentation available online regarding their installation and customization.<br />
<!--l. 311--></p>
<h5 class="subsubsectionHead"><span class="titlemark">5.1.3 </span> <a id="x1-230005.1.3"></a>Environmental Variables</h5>
<p><!--l. 312--></p>
<p class="noindent">Environment variables are values that pertain to certain aspects of an operating system’s configurations. These variables are typically used by utilities and programs for things like finding out where the user’s home directory is (<code>$HOME</code>) or where to look for executable files (<code>$PATH</code>). The prompt for BASH is held as the variable <code>PS1</code>.<br />
<!--l. 314--></p>
<p class="indent">You can print the environment variable to the screen using the <code>echo</code> command:</p>
<pre>echo $HOME</pre>
<p><!--l. 317--></p>
<p class="nopar"><!--l. 319--></p>
<p class="indent">A good way to view environment variables that are set is by using the <code>env</code> command</p>
<pre>env</pre>
<p><!--l. 322--></p>
<p class="nopar">which outputs all of the variables currently in use.<br />
<!--l. 325--></p>
<p class="indent">To change the value of an existing variable or to create and set a new variable, we use <code>export</code>. For example, to set a variable called <code>workDir</code> to a directory called here within your home directory, the command would be:</p>
<pre>export workDir=$HOME/here</pre>
<p><!--l. 328--></p>
<p class="nopar">Once this environment variable is set, you are able to use this. For example, to change to this directory, the command would be:</p>
<pre>cd $workDir</pre>
<p><!--l. 332--></p>
<p class="nopar"><!--l. 334--></p>
<p class="indent">For something like PATH where you really do not want to overwrite what values are already stored, you can append values with</p>
<pre>export PATH=$PATH:/new/dir/path/</pre>
<p><!--l. 337--></p>
<p class="nopar">In lists of values, the colon (<code>:</code>) is used as the delimiter. The dollar sign (<code>$</code>) is used to reference variables, so that export command essentially appends the new directory to the list of existing directories searched for executables. It is possible to prepend as well, which may come in handy if you compile a different version of an existing command.<br />
<!--l. 340--></p>
<p class="indent">For more general reading on environment variables in Linux, see these pages on <a href="http://tldp.org/LDP/Bash-Beginners-Guide/html/sect_03_02.html">variables</a> and <a href="https://en.wikipedia.org/wiki/Environment_variable">environmental variables</a>.<br />
<!--l. 342--></p>
<p class="indent">The environment variables allow for script portability between different systems. By referencing variables like the home directory ($HOME) you can generalize a script’s functionality to work across systems and accounts.</p>

<table id="tablepress-7" class="tablepress tablepress-id-7">
<thead>
<tr class="row-1 odd">
	<th class="column-1">Variable Name</th><th class="column-2">Description</th>
</tr>
</thead>
<tbody class="row-hover">
<tr class="row-2 even">
	<td class="column-1">USER</td><td class="column-2">Your user ID</td>
</tr>
<tr class="row-3 odd">
	<td class="column-1">HOSTNAME</td><td class="column-2">The name of the server that the script is being run on</td>
</tr>
<tr class="row-4 even">
	<td class="column-1">HOME</td><td class="column-2">Your home directory</td>
</tr>
<tr class="row-5 odd">
	<td class="column-1">WORK</td><td class="column-2">Your work directory</td>
</tr>
<tr class="row-6 even">
	<td class="column-1">SCRATCH</td><td class="column-2">Your scratch directory</td>
</tr>
<tr class="row-7 odd">
	<td class="column-1">TMPDIR</td><td class="column-2">The directory in which a job's temporary files are placed (created and deleted automatically)</td>
</tr>
</tbody>
</table>
<!-- #tablepress-7 from cache -->
<p><!--l. 355--></p>
<h5 class="subsubsectionHead"><span class="titlemark">5.1.4 </span> <a id="x1-240005.1.4"></a>References</h5>
<p><!--l. 357--></p>
<p class="noindent">The Linux terminal and submitting jobs are not unique to Roar. You can find many different training resources online for these. The Linux foundation offers <a href="https://training.linuxfoundation.org/free-linux-training">free training</a>. Lots of great information and tutorials for everyone from beginner Linux user to advanced users can be found <a href="https://www.linux.org/pages/download/">here</a>. Linux has been around for a long time. Therefore, any problem you might be having, someone has probably already had. It is always worthwhile to look around <a href="https://unix.stackexchange.com/">stack exchange</a> to see if your question has already been answered.</p>
<p class="indent"><!--l. 456--></p>




	<a name="05-02-module-system"></a><br>
	<h4>5.2 Module System</h4>
	<p><!--l. 363--></p>
<p class="noindent">Roar now uses the Lmod environment modules system. Environment Modules provide a convenient way to dynamically change the users environment through modulefiles. This includes easily adding or removing directories to the <code>PATH</code>, <code>LD_LIBRARY_PATH</code>, <code>MANPATH</code>, and <code>INFOPATH</code> environment variables. A modulefile contains the necessary information to allow a user to run a particular application or provide access to a particular library. All of this can be done dynamically without logging out and back in. Modulefiles for applications modify the users path to make access easy. Modulefiles for library packages provide environment variables that specify where the library and header files can be found. Learn more about modules on <a href="https://www.tacc.utexas.edu/research-development/tacc-projects/lmod">TACC&#8217;s website</a>.</p>
<p><!--l. 365--></p>
<h5 class="subsubsectionHead"><span class="titlemark">5.2.1 </span> <a id="x1-260005.2.1"></a>Module Families</h5>
<p><!--l. 366--></p>
<p class="noindent">Roar uses module families for compilers and parallelization libraries. Modules that are built with a parent module, such as a compiler, are only available when the parent module is loaded. For example, the version of LAPACK built with the gcc module is only available when the gcc module is located.</p>
<p><!--l. 368--></p>
<p class="indent">A good way to illustrate how the module families work is to view the available modules before a family is loaded as well as after. You can do this with the gcc family by inspecting the output of</p>
<pre class="script">module purge

module avail

module load gcc/8.3.1

module avail

</pre>
<p><!--l. 374--></p>
<p class="nopar"><!--l. 376--></p>
<h5 class="subsubsectionHead"><span class="titlemark">5.2.2 </span> <a id="x1-270005.2.2"></a>Using Modules</h5>
<p><!--l. 377--></p>
<p class="noindent">You can load modules into your environment with the command with the module load command. For example, to load the gcc module, you can use the command:</p>
<pre>module load gcc/8.3.1</pre>
<p><!--l. 380--></p>
<p class="nopar">Note that the version number is not required. Each software will have a default module that will be loaded if no version number is provided. However, it is recommended that you put the version number so that you know and have a record of what version is being used.<br />
<!--l. 383--></p>
<p class="indent">You can view the modules that you currently have open using the module list command:</p>
<pre>module list</pre>
<p><!--l. 386--></p>
<p class="nopar"><!--l. 388--></p>
<p class="indent">You can also unload modules that you do not need in the same way:</p>
<pre>module unload gcc/8.3.1</pre>
<p><!--l. 391--></p>
<p class="nopar"><!--l. 393--></p>
<p class="indent">It is also possible to remove all of your loaded modules at once using purge:</p>
<pre>module purge</pre>
<p><!--l. 396--></p>
<p class="nopar"><!--l. 400--></p>
<h5 class="subsubsectionHead"><span class="titlemark">5.2.3 </span> <a id="x1-280005.2.3"></a>Querying Modules</h5>
<p><!--l. 402--></p>
<p class="noindent">You can view the available modules using the command:</p>
<pre>module avail</pre>
<p><!--l. 405--></p>
<p class="nopar"><!--l. 407--></p>
<p class="indent">Note that this only looks at the available modules, which may be limited by module family based on modules are currently loaded. You can search all of the modules using <code>module spider</code>. For example, to search for VASP, you can use the command</p>
<pre>module spider vasp</pre>
<p>which will search through all module names and module files to return anything related to vasp.<br />
<!--l. 410--></p>
<p class="nopar"><!--l. 412--></p>
<p class="indent">The module can be used to give you information about the software using the module show command. For<br />
example, the information about the hdf5 module, which was built using the gcc module, can be seen using the commands:</p>
<pre class="script">module load gcc/8.3.1

module show hdf5/1.10.7

</pre>
<p><!--l. 416--></p>
<p class="nopar"><!--l. 418--></p>
<p class="indent">The output of this is shown:</p>
<pre class="script">---------------------------------------------------------------------

/opt/aci/modulefiles/Compiler/gcc/8.3.1/hdf5/1.10.7.lua:

---------------------------------------------------------------------

help([[HDF5 is a unique technology suite that makes possible the management of extremely large and complex data collections. The HDF5 technology suite includes: A versatile data model that can represent very complex objects and a variety of metadata. A completely portable file format with no limit on the number or size of data objects in the collection. A software library that runs on a range of computational platforms, from laptops to massively parallel systems, and implements a high-level API with C, C++, Fortran 90, and Java interfaces. A rich set of integrated performance features that allow for access time and storage space optimizations. Tools and applications for managing, manipulating, viewing, and analyzing the data in the collection.
]])

whatis("Description: HDF5 is a unique technology suite that makes possible the management of extremely large and complex data collections.")

whatis("URL: https://support.hdfgroup.org/HDF5/")

prepend_path("PATH","/opt/aci/sw/hdf5/1.8.18_gcc-8.3.1/bin")

prepend_path("LD_LIBRARY_PATH","/opt/aci/sw/hdf5/1.8.18_gcc-8.3.1/lib64")

prepend_path("C_INCLUDE_PATH","/opt/aci/sw/hdf5/1.8.18_gcc-8.3.1/include")

prepend_path("CPLUS_INCLUDE_PATH","/opt/aci/sw/hdf5/1.8.18_gcc-8.3.1/include")

prepend_path("LIBRARY_PATH","/opt/aci/sw/hdf5/1.8.18_gcc-8.3.1/lib64")

pushenv("HDF5","/opt/aci/sw/hdf5/1.8.18_gcc-8.3.1")

pushenv("HDF","/opt/aci/sw/hdf5/1.8.18_gcc-8.3.1")

</pre>
<p><!--l. 434--></p>
<p class="nopar"><!--l. 436--></p>
<p class="indent">Note that this tells you some information about the software, gives a website for more help and shows the environment variables that are modified. The environment manipulation section can be very helpful for users who are compiling codes and linking to libraries as these paths indicate where the relevant objects may be found.<br />
<!--l. 439--></p>
<h5 class="subsubsectionHead"><span class="titlemark">5.2.4 </span> <a id="x1-290005.2.4"></a>Controlling Modules Loaded at Login</h5>
<p><!--l. 440--></p>
<p class="noindent">Most shells have a configuration file that allows you to set aliases (nicknames for commands both simple or complex), set environment variables, and automatically execute programs and commands. In this case we are interested in the last mentioned feature: automating commands at login. For BASH there are two files at play: <code>~/.bash_profile</code> and <code>~/.bashrc.</code> To force your bashrc to be sourced in every opened terminal and SSH session, include this code in your bash_profile:</p>
<pre>if [ -f ~/.bashrc ]; then

. ~/.bashrc

fi
</pre>
<p><!--l. 445--></p>
<p class="nopar"><!--l. 447--></p>
<p class="indent">Once that has been done, you can add whatever automated module loads you want in the .bashrc file by including:</p>
<pre>module load &lt;module name&gt;/&lt;version&gt;</pre>
<p><!--l. 451--></p>
<p class="nopar"><!--l. 453--></p>
<p class="indent">The version specification is optional, excluding it will cause whatever the default version is to be loaded. Other shells have similar configuration methods that are detailed in online documentation.</p>




	<a name="05-03-connecting-aci-b"></a><br>
	<h4>5.3 Connecting to ACI-b</h4>
	<p><!--l. 457--></p>
<p class="noindent">Users can connect to ACI-b with the hostname</p>
<pre>submit.aci.ics.psu.edu</pre>
<p><!--l. 460--></p>
<p class="nopar">using <code>ssh</code>. Users  connecting with ssh are encouraged to use the secure x-window forwarding flag (<code>-Y</code>) if x-windows will be used during the session. Note that the screen may not show * symbols for each keystroke when your password is being entered. (In this example, the username is &#8220;abc123&#8221;.)</p>
<pre>ssh -Y abc123@submit.aci.ics.psu.edu</pre>
<p><!--l. 464--></p>
<p class="nopar"><!--l. 466--></p>




	<a name="05-04-connecting-aci"></a><br>
	<h4>5.4 Connecting to ACI-i</h4>
	<p><!--l. 467--></p>
<p class="noindent">Users connect to ACI-i with Open OnDemand.</p>
<p><!--l. 474--></p>
<p class="nopar"><!--l. 476--></p>
<p><!--l. 477--></p>




	<a name="05-041-open-ondemand"></a><br>
	<h4>5.4.1 Open OnDemand</h4>
	<p>Open OnDemand lets you utilize Penn State’s high performance computing resources in a graphical, menu-based environment that doesn&#8217;t require using an ssh client. Interacting with Roar with Open OnDemand looks and feels like the desktop or web-based applications you’re used to.</p>
<p>Open OnDemand is accessed through your web browser, so there’s nothing to download or install.<br />
Simply go to this web address:</p>
<p>PORTAL.ACI.ICS.PSU.EDU</p>
<p><strong>Note:</strong> When accessing Roar on Open OnDemand, you&#8217;ll see a CILogon screen before you can enter your Penn State ID and password. Simply click the <strong>Log On</strong> button to proceed.</p>
<h3>Introduction to Using Open OnDemand on Roar (formerly known as ICDS-ACI)</h3>
<p><iframe loading="lazy" src="https://www.youtube.com/embed/ekiz0o94pwQ" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"><span data-mce-type="bookmark" style="display: inline-block; width: 0px; overflow: hidden; line-height: 0;" class="mce_SELRES_start">﻿</span></iframe></p>




	<a name="05-05-connecting-to-hprc"></a><br>
	<h4>5.5 Connecting to HPRC</h4>
	<p>Users can connect to HPRC from ACI-b head nodes, with the host name</p>
<pre>submit.aci.ics.psu.edu</pre>
<p>…using ssh. Users connecting with ssh are encouraged to use the secure x-window forwarding flag (-Y) if x-windows will be used during the session. Note that the screen may not show * symbols for each keystroke when your password is being entered. (In this example, the username is “abc123”.)</p>
<pre>ssh -Y abc123@submit.aci.ics.psu.edu</pre>




	<a name="05-06-transferring-data-aci"></a><br>
	<h4>5.6 Transferring Data to and from Roar</h4>
	<p class="noindent">There are many different ways to transfer data to and from Roar.<br />
<!--l. 504--></p>
<h5 class="subsubsectionHead"><span class="titlemark">5.6.1 </span> <a id="x1-340005.5.1"></a>Command line File Transfer</h5>
<p><!--l. 506--></p>
<p class="noindent">There are two main command-line SSH commands to transfer files: <code>scp</code> and <code>sftp</code>. <code>scp</code> is a non-interactive command that takes a set of files to copy on the command line, copies them, and exits. <code>sftp</code> is an interactive command that opens a persistent connection through which multiple copying commands can be performed.<br />
<!--l. 510--></p>
<p class="indent"><strong>scp</strong><br />
To copy one or more local files up to the Roar server, the <code>scp</code> syntax would be:</p>
<pre>scp local_file &lt;username&gt;@datamgr.aci.ics.psu.edu:&lt;target_directory&gt;</pre>
<p><!--l. 514--></p>
<p class="nopar"><!--l. 516--></p>
<p class="indent">The default port for scp is set to 22. If you use this port you will be automatically directed to Duo Push authentication during 2FA.<br />
<!--l. 518--></p>
<p class="indent">For user abc123 to copy the local files foo.c and foo.h into their home directory on the host aci-b.aci.ics.psu.edu, the following command would be used:</p>
<pre>[abc123@local ~]$ scp foo.c foo.h abc123@datamgr.aci.ics.psu.edu:~/.</pre>
<p><!--l. 523--></p>
<p class="nopar"><!--l. 525--></p>
<p><!--l. 528--></p>
<p class="nopar"><!--l. 530--></p>
<p class="indent">The <span class="cmbx-10">-r </span>(recursive) flag can be used to transfer directories.</p>
<pre>[abc123@local ~]$ scp -r dirA abc123@datamgr.aci.ics.psu.edu:~/.</pre>
<p><!--l. 534--></p>
<p class="nopar"><!--l. 536--></p>
<p class="indent">Users can also copy files from Roar onto their own computer using</p>
<pre>[abc123@local ~]$ scp abc123@datamgr.aci.ics.psu.edu:~/fileA .</pre>
<p><!--l. 539--></p>
<p class="nopar"><!--l. 541--></p>
<p class="indent"><!--l. 543--></p>
<p class="indent"><strong>sftp</strong><br />
<code>sftp</code> is an interactive command that uses the same syntax as a standard command-line ftp client. It differs from a standard ftp client in that the authentication and the data transfer happen through the SSH protocol rather than the FTP protocol. The SSH protocol is encrypted whereas the FTP protocol is not.<br />
<!--l. 545--></p>
<p class="indent">There are a number of basic commands that are used inside of <code>stfp</code>:</p>
<ul class="itemize1">
<li class="itemize"><code>put filename</code>: uploads the file filename</li>
<li class="itemize"><code>get filename</code>: downloads the file filename</li>
<li class="itemize"><code>ls</code>: lists the contents of the current remote directory</li>
<li class="itemize"><code>lls</code>: lists the contents of the current local directory</li>
<li class="itemize"><code>pwd</code>: returns the current remote directory</li>
<li class="itemize"><code>lpwd</code>: returns the current local directory</li>
<li class="itemize"><code>cd directory</code>: changes the current remote directory to directory</li>
<li class="itemize"><code>lcd directory</code>: changes the current local directory to directory</li>
</ul>
<p><!--l. 557--></p>
<p class="indent">The syntax for calling <code>sftp</code> is:</p>
<pre>sftp username@hostname</pre>
<p><!--l. 560--></p>
<p class="nopar"><!--l. 562--></p>
<p class="indent">To choose between different options for 2FA you have to set the port to 1022 using P flag similar to <code>ssh</code>.<br />
<!--l. 564--></p>
<p class="indent">An example <code>sftp</code> session, with both the inputs and outputs, would be:</p>
<pre class="script">[abc123@local ~]$ sftp abc123@submit.aci.ics.psu.edu

Connecting to submit.aci.ics.psu.edu...

Password: &lt;user abc123 password&gt;

# Duo Push authentication

Connected to aci-b.aci.ics.psu.edu.

sftp&gt; pwd

Remote working directory: /storage/home/abc123

sftp&gt; lpwd

Local working directory: /home/abc123

sftp&gt; cd work/depot

sftp&gt; pwd

Remote working directory: /storage/work/abc123/depot

sftp&gt; lcd results

sftp&gt; lpwd

Local working directory: /home/abc123/results

sftp&gt; ls -l

-rw-r--r--

1 root

root

5 Mar

3 12:08 dump

sftp&gt; lls -l

total 0

sftp&gt; get dump

Fetching /storage/work/abc123/depot/dump to dump

/storage/work/abc123/depot/dump

100%

5

0.0KB/s

0.0KB/s

00:00

sftp&gt; lls -l

total 4

-rw-r--r-- 1 abc123 abc123 5 Mar

3 12:09 dump

sftp&gt; put data.txt

Uploading data.txt to /storage/work/abc123/depot/data.txt

data.txt

100%

15

0.0KB/s

sftp&gt;

</pre>
<p><!--l. 608--></p>
<p class="nopar"><!--l. 610--></p>
<p class="indent"><!--l. 612--></p>
<p class="indent"><strong>rsync</strong><br />
<code>rsync</code> is a utility that can be used to copy files and for keeping files the same on different systems as a rudimentary version control system. The benefit to using <code>rsync</code> over <code>scp</code> is that if an <code>scp</code> is stopped for any reason (poor wireless connection, large files, etc) the restart will begin as if no files were copied over. The <code>rsync</code> utility will only copy the files that were not successfully moved over in the previous command. Once you have SSH access between two machines, you can synchronize dir1 folder ( home directory in this example) from local to a remote computer by using syntax:</p>
<pre>rsync -a ~/dir1 username@remote_host:destination_directory</pre>
<p><!--l. 615--></p>
<p class="nopar"><!--l. 617--></p>
<p class="indent">where remote host is the Roar host name as in scp command. If dir1 were on the remote system instead of the local system, the syntax would be:</p>
<pre>rsync -a username@remote_host:/home/username/dir1 place_on_local_machine</pre>
<p><!--l. 620--></p>
<p class="nopar"><!--l. 622--></p>
<p class="indent">If you are transferring files that have not been compressed yet, like text files, you can reduce the network transfer by adding compression with the <code>-z</code> option:</p>
<pre>rsync -az source_dir username@remote_host:target_dir</pre>
<p><!--l. 625--></p>
<p class="nopar"><!--l. 627--></p>
<p class="indent">The -P flag is very helpful. It combines the flags –progress and –partial. The former gives you a progress bar for the transfers and the latter allows you to resume interrupted transfers:</p>
<pre>rsync -azP source_dir username@remote_host:target_dir</pre>
<p><!--l. 630--></p>
<p class="nopar"><!--l. 632--></p>
<p class="indent">In order to keep two directories synchronized it is necessary to delete files from the destination directory if they are removed from the source. rsync does not delete anything from the destination directory by default. To change this behavior use the <code>–delete</code> option:</p>
<pre>rsync -a --delete source_dir username@remote_host:taget_dir</pre>
<p><!--l. 635--></p>
<p class="nopar">If you wish to exclude certain files or directories located inside a directory you are syncing, you can do so by specifying them in a comma-separated list following <code>–exclude=</code> option:</p>
<pre>rsync -a --exclude=pattern_to_exclude source_dir username@remote_host:target_dir

</pre>
<p class="nopar">One common pitfall that can affect users transferring files between systems with different usernames and groups can be the permissions assigned to the files being <code>rsync</code>-ed. The <code>--chmod</code> option can be used both to set the permissions for the user, group and other independently, as well as to set any directory permissions for inheritance of files created within the directory after the transfer is complete.  Multiple commands can be strung together using commas. For example, the following will provide full permissions for the user, read and execute permissions for others in the group and will cause all of the future files created within any directories being transferred to inherit the group that the directory has.</p>
<pre>rsync -a--chmod u=rwx,g=rx,Dg+s source_dir username@remote_host:target_dir</pre>
<p><!--l. 640--></p>
<p class="nopar"><!--l. 642--></p>
<h5 class="subsubsectionHead"><span class="titlemark">5.6.2 </span> <a id="x1-350005.5.2"></a>Graphical File Transfer</h5>
<p><!--l. 643--></p>
<p class="noindent">WinSCP and FileZilla provide a free secure FTP (SFTP) and secure copy (SCP) client with graphical interface for Windows, Linux and Mac using SSH, allowing users to transfer files to and from our cluster file system using a drag-and-drop interface. Please use either the SCP or SFTP protocol with port 22 with the data manager nodes</p>
<pre>datamgr.aci.ics.psu.edu</pre>
<p><!--l. 646--></p>
<p class="nopar">to transfer files. Please note that your two factor authentication is required.<br />
<!--l. 649--></p>
<p class="indent">For more information, please visit the <a href="http://winscp.net/eng/index.php">WinSCP homepage</a> or the <a href="https://filezilla-project.org/">FileZilla homepage</a>.<br />
<!--l. 653--></p>
<p class="indent">You can see the connection process in this <a href="https://www.youtube.com/watch?v=pOJaKeA89lI&amp;t=2s">ICDS tutorial video</a>.<br />
<!--l. 657--></p>
<p class="indent">It is also possible to use the online interface for either Box or DropBox within Firefox on ACI-i for users who logged on with Open OnDemand. It is not currently possible to sync to your storage space on Roar at this time.<br />
<!--l. 660--></p>
<h5 class="subsubsectionHead"><span class="titlemark">5.6.3 </span> <a id="x1-360005.5.3"></a>Web-based Services</h5>
<p><!--l. 662--></p>
<p class="noindent">Globus is one of the recommended methods of transferring very large data. Most HPC centers have endpoints set up allowing for optimized transfer between large centers. Users can also install personal endpoints on their own machines using Globus Connect. Its web interface allows users to transfer files from a desktop or mobile device.<br />
<!--l. 664--></p>
<p class="indent">Users must sign up for a <a href="http://globus.org">globus</a><a href="http://globus.org"> account</a> as this is a separate service from Roar. An endpoint is a location to/from which the files are to be transferred. There are 2 types of endpoints: server endpoints (like Roar) and personal endpoints (user’s laptop). To save or bookmark endpoints go to Manage Endpoints section on the globus webpage (you have to be logged in). Then click add Globus Connect Personal In Step 1 you have to define the name for your personal endpoint and click on Generate Setup Key. Copy the key to the clipboard. In Step 2 you have to download and install Globus Connect Personal app appropriate for your OS. To finish the installation you will be asked to paste the generated key which you copied to the clipboard. Each time you want to transfer file you will have to have the Globus Connect Personal running on your local computer. If you do not have a Globus account, create one <a href="https://www.globus.org.">here</a>. Set up a free Globus Online account using your PSU ID. If you wish to use Globus to transfer data to/from your local computer, install the Globus Connect Personal tool on your computer. More information on the Instructions for Installing Globus Connect Personal tool for linux can be found <a href="https://docs.globus.org/how-to/globus-connect-personal-linux/">here.</a> Instructions for <a href="https://docs.globus.org/how-to/globus-connect-personal-mac/">mac</a> and <a href="https://docs.globus.org/how-to/globus-connect-personal-windows/">windows</a> are also available.</p>
<p class="indent">On the Globus Start Transfer page, choose one of three Roar end points (for example <code>PennState_ICS-ACI_DTN_EndPnt_01</code>) as the end point on one side. This will pull up an authentication window. Use your Penn State ID for the user name, and your Penn State ID password for the pass phrase. This will set up an authenticated session.<br />
<!--l. 676--></p>
<p class="indent">Select and authenticate with the other endpoint for your transfer, and initiate your transfer. You may need to click on refresh list if you can’t see the transferred files despite the transfer has completed.<br />
<!--l. 679--></p>
<p class="indent">There are other specialized data-transfer software available for specific needs, such as Aspera. Contact the iAsk center if you have any questions regarding using one of these specialized tools on ACI.<br />
<!--l. 681--></p>
<h5 class="subsubsectionHead"><span class="titlemark">5.6.4 </span> <a id="x1-370005.5.4"></a>File Permissions</h5>
<p><!--l. 682--></p>
<p class="noindent">File permissions can be seen using the <code>-l</code> flag for ls:</p>
<pre>ls -l</pre>
<p><!--l. 685--></p>
<p class="nopar"><!--l. 687--></p>
<p class="indent">The letters at the beginning indicate the file or folder permissions while the third and fourth columns show the owner and group associated with the file. The letters used are typically rwx, for read, write and execute. These are grouped in sets of three, the first set for the owner, the second for the group and the third for the entire world. Users may change permissions using the chmod command. An excellent overview of how to change permissions using chmod can be found <a href="http://catcode.com/teachmod/">here.</a></p>
<p>Users may also want to change the group of their files using the <code>chgrp</code> command.</p>




	<a name="06-00-application-development"></a><br>
	<h3>6 Application Development</h3>
	<p class="noindent">
<!--l. 728--></p>




	<a name="06-01-version-control"></a><br>
	<h4>6.1 Version Control</h4>
	<p class="noindent">Version control is a way to track multiple versions of a code.  This has a place in development, primarily with adding new features while still using the original code or with multiple developers, and if the code has minor variants for reasons such as slightly different input/output data types or for use on different compute resources. One popular version control tool is <code>git</code>, which uses a distributed approach which allows for many development points. The basic <code>git</code> workflow is to</p>
<ul class="itemize1">
<li class="itemize">Modify files &#8211; create new code, fix bugs, etc. </li>
<li class="itemize">Stage the files &#8211; explicitly state what will be deposited</li>
<li class="itemize">Commit your files &#8211; store a snapshot</li>
</ul>
<p class="noindent">Your repository will have a master branch, where the current production code usually exists, and other branches that may be for any other purpose, such as development or variations.  Branches can either be merged back to the master branch as features are added and execution is validated, or kept separate if the usage requires multiple working versions of the code. It is up to the user to define how their repository is set-up as well as to keep non-local versions of the repository as up-to-date as desired.  There are great online resources for <code>git</code> including <a href="http://git-scm.com/doc">excellent documentation</a> and <a href="http://try.github.io">tutorials</a>.</p>




	<a name="06-02-basic-compilation"></a><br>
	<h4>6.2 Basic Compilation</h4>
	<p class="noindent">You can your own compile code for running on Roar. A basic compilation might look like</p>
<pre>gcc -O2 -lm -o hello.out hello.c &lt;\pre&gt;</pre>
<p class="noindent">where the gnu compiler is used to compile a C code in the file hello.c.</p>
<ul class="itemize1">
<li class="itemize"><code>gcc</code> Compiler being used</li>
<li class="itemize"><code>-O2</code> Optimization Flag</li>
<li class="itemize"><code>-lm</code> Link to the math library</li>
<li class="itemize"><code>-o hello.out</code> Output file</li>
<li class="itemize"><code>hello.c</code> Input file</li>
</ul>
<p class="noindent">It&#8217;s possible to link to pre-compiled libraries that are created by you or that already exist on the system. The <code>module show </code> command can be very useful in determining the locations of the libraries and header files required to compile codes. You can link in a variety of ways.</p>
<ul class="itemize1">
<li class="itemize"><code>-L</code> (as in Love) Path to a directory containing a library</li>
<li class="itemize"><code>-l</code> (as in love) Library name</li>
<li class="itemize"><code>-I</code> (as in Iowa) Path to header files</li>
</ul>
<p class="noindent">Complicated compilations can also be done using a build automation software package such as <code>make</code>, which is available without a module, or <code>cmake</code>, which is available as a module. The general build automation process involves using a Makefile that has:</p>
<ul class="itemize1">
<li class="itemize">Outputs &#8211; the executable/library being created</li>
<li class="itemize">Dependencies &#8211; what each output relies on</li>
<li class="itemize">Instructions &#8211; how to make/find each dependency</li>
</ul>
<p class="noindent">and can set environment variables. The nomenclature for repeated sections can use regex and so can be very complicated. Information about these tools can be found in online references, such as the <a href="http://gnu.org/software/make/manual/make.html">make</a> and <a href="https://cmake.org/documentation/">cmake</a> manuals. Some common pitfalls that the iAsk center sees for using make are:</p>
<ul class="itemize1">
<li class="itemize">Makefiles require tabs and not spaces at the beginning of indented lines</li>
<li class="itemize">The <code>-j</code> flag and an integer can be used to compile on multiple processors</li>
<li class="itemize">The <code>-f</code> flag can be used to specify the name of the makefile if not Makefile</li>
<li class="itemize">Some makefiles are configured for the compute environment. You may need to use the command <code>./configure</code> if there isn&#8217;t a make file and configure scripts exist./li&gt;</li>
</ul>
<p class="noindent">It is possible to either make the output file directly executable and add the location to your path to call this from anywhere, or to execute the output from the location of the file directly. For our hello example from before, this can be done using the command <code>./hello.out</code> from the directory in which the executable exists.</p>




	<a name="06-03-libraries"></a><br>
	<h4>6.3 Libraries</h4>
	<p class="noindent">Roar offers many optimized libraries for users to link to. Please see the most common libraries listed below.<br />
<!--l. 732--></p>
<h5 class="subsubsectionHead"><span class="titlemark">6.3.1 </span> <a id="x1-400006.3.1"></a>MKL</h5>
<p><!--l. 734--></p>
<p class="noindent">Intel Math Kernel Library (MKL) consists of commonly used mathematical operations in computational science. The functions in MKL are optimized for use on Intel processors. More information can be found <a href="https://software.intel.com/en-us/mkl">here.</a><br />
<!--l. 737--></p>
<p class="indent">The MKL module can be loaded using the command</p>
<pre>module load mkl</pre>
<p><!--l. 740--></p>
<p class="nopar"><!--l. 742--></p>
<h5 class="subsubsectionHead"><span class="titlemark">6.3.2 </span> <a id="x1-410006.3.2"></a>LAPACK</h5>
<p><!--l. 745--></p>
<p class="noindent">LAPACK (Linear Algebra Package) is a software library used for numerical linear algebra. It can handle many common numerical algebra computations such as solving linear systems, eigenvalue problems, and matrix factorization. It depends on BLAS. More information can be found on the <a href="http://www.netlib.org/lapack/">website.</a><br />
<!--l. 747--></p>
<p class="indent">You can load the LAPACK module using the commands:</p>
<pre>module load gcc/5.3.1
module load lapack/3.6.0
</pre>
<p><!--l. 751--></p>
<p class="nopar"><!--l. 753--></p>
<h5 class="subsubsectionHead"><span class="titlemark">6.3.3</span> <a id="x1-420006.3.3"></a>BLAS</h5>
<p><!--l. 755--></p>
<p class="noindent">BLAS (Basic Linear Algebra Subprograms) is a collection of low level matrix and vector operations such as vector addition, scalar multiplication, matrix multiplication, etc. For more information, refer to this <a href="http://www.netlib.org/blas/">link.</a><br />
<!--l. 757--></p>
<p class="indent">The BLAS module can be loaded with the command</p>
<pre>module load blas</pre>
<p><!--l. 760--></p>
<p class="nopar"><!--l. 762--></p>
<h5 class="subsubsectionHead"><span class="titlemark">6.3.5 </span> <a id="x1-440006.3.5"></a>Boost</h5>
<p><!--l. 770--></p>
<p class="noindent">Boost is a C++ library that contains many useful functions covering a wide range of applications such as linear algebra and multithreading. More information can be found <a href="http://www.boost.org/">here.</a></p>
<p class="noindent">You can load Boost with the command</p>
<pre>module load boost</pre>
<p><!--l. 775--></p>
<p class="nopar"><!--l. 777--></p>
<h5 class="subsubsectionHead"><span class="titlemark">6.3.6 </span> <a id="x1-450006.3.6"></a>PETsc</h5>
<p><!--l. 778--></p>
<p class="noindent">The Portable, Extensible Toolkit for Scientific Computation (PETsc, pronounced PET-see) is a suite of data structures and routines for solving partial differential equations and sparse matrices in a parallel fashion that is scalable. It was developed by Argonne National Laboratory.<br />
<!--l. 780--></p>
<p class="indent">You can load the PETsc module using the command</p>
<pre>module load petsc/3.8.3</pre>
<p><!--l. 783--></p>
<p class="nopar"><!--l. 785--></p>
<p class="indent">More information on features, tutorials, manuals, etc can be found on the <a href="http://www.mcs.anl.gov/petsc/">website.</a></p>




	<a name="07-00-running-jobs-on-aci-b"></a><br>
	<h3>7 Running Jobs on ACI-b</h3>
	<p class="noindent">Jobs are submitted from the head nodes of ACI-b and will run when dedicated resources are available on the compute nodes. Roar uses Moab and Torque for the scheduler and resource manager. Jobs can be either run in batch or interactive modes. Both are submitted using the qsub command.<br />
<!--l. 805--></p>
<div id="verbatim-64" class="verbatim"></div>




	<a name="07-01-requesting-resources"></a><br>
	<h4>7.1 Requesting Resources</h4>
	<p><!--l. 807--></p>
<p class="noindent">Both batch and interactive jobs are required to provide a list of requested resources to the scheduler in order to be placed on a compute node with the correct resources available. These are given either in the submission script or on the command line. If these are given in a submission script, they must come before any non-PBS command.<br />
<!--l. 809--></p>
<p class="indent">Typical PBS directives are:</p>

<table id="tablepress-8" class="tablepress tablepress-id-8">
<thead>
<tr class="row-1 odd">
	<th class="column-1">PBS Directive</th><th class="column-2">Description</th>
</tr>
</thead>
<tbody class="row-hover">
<tr class="row-2 even">
	<td class="column-1">#PBS -l walltime=HH:MM:SS</td><td class="column-2">This specifies the maximum wall time (real time, not CPU time) that a job should take. If this limit is exceeded, PBS will stop the job. Keeping this limit close to the actual expected time of a job can allow a job to start more quickly than if the maximum wall time is always requested.</td>
</tr>
<tr class="row-3 odd">
	<td class="column-1">#PBS -l pmem=SIZEgb</td><td class="column-2">This specifies the maximum amount of physical memory used by any processor ascribed to the job. For example, if the job would run on four processors and each would use up to 2 GB (gigabytes) of memory, then the directive would read #PBS -l pmem=2gb. The default for this directive is 1 GB of memory.</td>
</tr>
<tr class="row-4 even">
	<td class="column-1">#PBS -l mem=SIZEgb</td><td class="column-2">This specifies the maximum amount of physical memory used in total for the job.  This should be used for single node jobs only.</td>
</tr>
<tr class="row-5 odd">
	<td class="column-1">#PBS -l nodes=N:ppn=M<br />
</td><td class="column-2">This specifies the number of nodes (nodes=N) and the number of processors per node (ppn=M) that the job should use. PBS treats a processor core as a processor, so a system with eight cores per compute node can have ppn=8 as its maximum ppn request. Note that unless a job has some inherent parallelism of its own through something like MPI or OpenMP, requesting more than a single processor on a single node is usually wasteful and can impact the job start time.</td>
</tr>
<tr class="row-6 even">
	<td class="column-1">#PBS -l nodes=N:ppn=M:O</td><td class="column-2">This specifies the node type (node type=O). You can only specify the node type when using the "Open Queue".   <br />
<br />
Node types available on Roar: <br />

<table id="tablepress-23" class="tablepress tablepress-id-23">
<thead>
<tr class="row-1 odd">
	<th class="column-1">Node Type = O</th><th class="column-2">CPU</th><th class="column-3">RAM</th>
</tr>
</thead>
<tbody class="row-hover">
<tr class="row-2 even">
	<td class="column-1">basic</td><td class="column-2">Intel Xeon E5-2650v4 2.2GHz </td><td class="column-3">128 GB Total</td>
</tr>
<tr class="row-3 odd">
	<td class="column-1">lcivybridge<br />
scivybridge</td><td class="column-2">Intel Xeon E5-2680v2 2.8GHz </td><td class="column-3">256 GB Total</td>
</tr>
<tr class="row-4 even">
	<td class="column-1">schaswell</td><td class="column-2">Intel Xeon E5-2680v3 2.5GHz </td><td class="column-3">256 GB Total</td>
</tr>
<tr class="row-5 odd">
	<td class="column-1">himem</td><td class="column-2">Intel Xeon E7-4830v2 2.2GHz </td><td class="column-3">1024 GB Total</td>
</tr>
</tbody>
</table>
</td>
</tr>
<tr class="row-7 odd">
	<td class="column-1">#PBS -A allocName</td><td class="column-2">This identifies the account to which the resource consumption of the job should be charged (SponsorID_collab). This flag is necessary for all job submissions. For jobs being submitted to a system’s open queue you should use -A open.</td>
</tr>
<tr class="row-8 even">
	<td class="column-1">#PBS -j oe</td><td class="column-2">Normally when a command runs it prints its output to the screen. This output is often normal output and error output. This directive tells PBS to put both normal output and error output into the same output file.</td>
</tr>
</tbody>
</table>
<!-- #tablepress-8 from cache -->
<p><!--l. 829--></p>
<h5 class="subsubsectionHead"><span class="titlemark">7.1.1 </span> <a id="x1-480007.1.1"></a>Sample Batch Submission Script</h5>
<p><!--l. 831--></p>
<p class="noindent">The following is a submission script for a Matlab job that will run for 5 minutes on one processor using the open queue.</p>
<pre class="script">#!/bin/bash

#PBS -l nodes=1:ppn=1

#PBS -l walltime=5:00

#PBS -A open

# Get started

echo "Job started on $(hostname) at $(date)"

# Load in matlab

module purge

module load matlab

# Go to the correct place

cd $PBS_O_WORKDIR

# Run the job itself - a matlab script called runThis.m

matlab-bin -nodisplay -nosplash &lt; runThis.m &gt; log.matlabRun

# Finish up

echo "Job Ended at $(date)"

</pre>
<p><!--l. 854--></p>
<p class="nopar"><!--l. 856--></p>
<p class="indent">This script would be submitted using the command</p>
<pre>qsub subScript.pbs</pre>
<p><!--l. 860--></p>
<p class="nopar">from the directory containing the submission and matlab scripts.<br />
<!--l. 863--></p>




	<a name="07-02-interactive-compute-sessions-aci-b"></a><br>
	<h4>7.2 Interactive Compute Sessions on ACI-b</h4>
	<p><!--l. 864--></p>
<p class="noindent">Interactive jobs may be submitted to ACI-b using the -I (for interactive) flag. Interactive jobs require resource requests and an allocation. An interactive job can be submitted using a command similar to:</p>
<pre>qsub -A open -l walltime=1:00:00 -l nodes=1:ppn=2 -I</pre>
<p><!--l. 867--></p>
<p class="nopar"><!--l. 869--></p>
<p class="indent">The job will be given a job ID and your session will wait until this job has the resources to start. You will then be placed on the compute node and given a usable terminal session within your current session. For example a user submitting an interactive job may see</p>
<pre class="script">[abc123@aci-lgn-001 ~]$ qsub I l nodes=1:ppn=1 l walltime=4:00:00 -A open

qsub: waiting for job <span style="word-wrap: break-word;">2449840.torque01.util.production.int.aci.ics.psu.edu</span> u to start

qsub: job <span style="word-wrap: break-word;">2449840.torque01.util.production.int.aci.ics.psu.edu</span> ready

[abc123@comp-bc-0267 ~]$

</pre>
<p><!--l. 877--></p>
<p class="nopar">Note that the node the user is on changes from log-in node (aci-lgn-001) to a basic core compute node (comp-bc-0267) when the job starts. You can ask for x-windows to be displayed using the <code>-X</code> flag with the <code>qsub</code> command, as long as you have logged into ACI-b using the <code>-Y</code> flag with <code>ssh</code>. Note that some users experiencing difficulty with interactive x-windows on ACI-b jobs will often use an Open OnDemand interactive session to connect to ACI-i, and then <code>ssh</code> with the <code>-Y</code> flag to ACI-b from ACI-i.<br />
<!--l. 880--></p>
<p class="indent">It is recommended that you compile your code using an interactive job on the nodes that your job will run.<br />
<!--l. 883--></p>
<div id="verbatim-64" class="verbatim"></div>




	<a name="07-03-pbs-environmental-variables"></a><br>
	<h4>7.3 PBS Environmental Variables</h4>
	<p><!--l. 885--></p>
<p class="noindent">Jobs submitted will automatically have several PBS environment variables created that can be used within the job submission script and scripts within the job. A full list of PBS environment variables can be used by viewing the output of</p>
<pre>env | grep PBS &gt; log.pbsEnvVars</pre>
<p><!--l. 888--></p>
<p class="nopar">run within a submitted job.</p>

<table id="tablepress-9" class="tablepress tablepress-id-9">
<thead>
<tr class="row-1 odd">
	<th class="column-1">Variable Name</th><th class="column-2">Description</th>
</tr>
</thead>
<tbody class="row-hover">
<tr class="row-2 even">
	<td class="column-1">PBS_O_WORKDIR</td><td class="column-2">The directory in which the qsub command was issued.</td>
</tr>
<tr class="row-3 odd">
	<td class="column-1">PBS_JOBID</td><td class="column-2">The job's id.</td>
</tr>
<tr class="row-4 even">
	<td class="column-1">PBS_JOBNAME</td><td class="column-2">The job's name.</td>
</tr>
<tr class="row-5 odd">
	<td class="column-1">PBS_NODEFILE</td><td class="column-2">A file in which all relevant node hostnames are stored for a job.</td>
</tr>
</tbody>
</table>
<!-- #tablepress-9 from cache -->
<p><!--l. 901--></p>
<h5 class="subsubsectionHead"><span class="titlemark">7.3.1 </span> <a id="x1-510007.3.1"></a>Viewing and Deleting Jobs</h5>
<p><!--l. 903--></p>
<p class="noindent">There are several ways to view existing jobs. The <code>qstat</code> command can give some basic information about your own queued and running jobs.</p>
<pre>qstat</pre>
<p><!--l. 906--></p>
<p class="nopar"><!--l. 908--></p>
<p class="indent">Some helpful flags are <code>-u</code> (user), <code>-s</code> (status), <code>-n</code> (to show the nodes running jobs are placed on) and -f to show more information for a specified job. For example, to view more information about job 536, you can use the command</p>
<pre>qstat -f 536</pre>
<p><!--l. 911--></p>
<p class="nopar"><!--l. 913--></p>
<p class="indent">Common status for jobs are Q for queued, R for running, E for ending, H for being held and C for complete.<br />
<!--l. 916--></p>
<p class="indent">You can also view all of the jobs running, waiting and being held using the showq command:</p>
<pre>showq</pre>
<p><!--l. 919--></p>
<p class="nopar"><!--l. 921--></p>
<p class="indent">It may be helpful for you to view all of the jobs running on an allocation. For example, if you are a member of the abc123_a_g_sc_default allocation, you can view the running and queued jobs using the command:</p>
<pre>showq -w acct=abc123_a_g_sc_default</pre>
<p><!--l. 924--></p>
<p class="nopar"><!--l. 927--></p>
<p class="indent">You may delete your jobs using the qdel command. For example, the job 546 may be deleted using the command:</p>
<pre>qdel 546</pre>
<p><!--l. 930--></p>
<p class="nopar"><!--l. 932--></p>
<p class="indent">Jobs that are not responding may require being purged from the nodes. You can do this with the <code>-p</code> flag:</p>
<pre>qdel -p 546</pre>
<p><!--l. 935--></p>
<p class="nopar"><!--l. 937--></p>
<p class="indent">Note that you are only able to delete your own jobs, not other users.<br />
<!--l. 940--></p>
<h5 class="subsubsectionHead"><span class="titlemark">7.3.2 </span> <a id="x1-520007.3.2"></a>Additional Job Information</h5>
<p><!--l. 942--></p>
<p class="noindent">You can use the checkjob command to view some additional information about queued and running jobs. For example, to give very verbose information about job 548, you can use the command:</p>
<pre>checkjob 548 -v -v</pre>
<p><!--l. 945--></p>
<p class="nopar"><!--l. 951--></p>




	<a name="07-04-great-allocations"></a><br>
	<h4>7.4 GReaT Allocations</h4>
	<p class="noindent">All jobs submitted to an allocation that have available resources are guaranteed to start within 1 hour. Note that the resources include both available hours as well as the requested resources. For example, a group that has a 40 core allocations on two standard memory nodes is limited to the RAM and CPUs on both nodes. Single processor jobs that request most of the memory on the nodes may block other jobs from running, even if CPUs are idle.<br />
<!--l. 955--></p>
<p class="indent">Users submitting to an allocation can run in ‘burst’ mode. Your group may use a number of cores up to four times your Core Limit (referred to as your 4x Core Limit). When your group submits jobs that exceed your Core Limit, you are considered to be ‘bursting,’ and your jobs will run on our Burst Queue. Bursting consumes your allocation faster than normal. How much you can burst is determined by your 90-day sliding window.<br />
<!--l. 957--></p>
<p class="indent">How much you can use Roar is governed by the size of your allocation and how much you have used the system in the past 90 days. In any given 90-day period, you may use up to your Core Limit times the number of hours in 90 days (2160). The amount of core-hours you have available is governed by a 90-day sliding window, such that the core-hours you use in any given day become available again after 90 days.<br />
<!--l. 959--></p>
<p><strong>How is My Allocation &#8220;Charged&#8221; for a Batch Job?</strong></p>
<p>The charge associated with a job is dependent on the total number of requested cores and the actual runtime of the job (in seconds):</p>
<p>NumberOfCores*Runtime.</p>
<p>For example, if a 20 core job has a total runtime of 1 hour the charge to the GReaT allocation is 20*3600=7200 core seconds. Please note that the charge includes the number of requested cores, not the number of utilized cores. Additionally, the requested walltime and actual runtime of the job may differ.</p>
<p><strong>Note:</strong> In the tables below, run times are noted in hours to simplify the examples. In practice, allocations are charged for usage by the second.</p>
<p class="indent"><span class="cmbx-10">Example: </span>If you have a 20-core allocation, you can consume 43,200 (20 * 2160) core-hours within any given 90-day period. Your average rate of usage in any 90-day period cannot exceed 20 cores per hour. Core-hours you use on the first day of your allocation will become available again on the 91st day; core-hours you use on the second day become available again on the 92nd day; and so on. If you never burst, you can use all your cores continuously.<br />
<!--l. 961--></p>
<p class="indent"><span class="cmbx-10">Example: </span>With your 20-core allocation, you run jobs requiring 20 cores continuously. In any given 90-day period, you will use 43,200 core-hours, and your average rate of usage is 20 cores per hour.</p>
<p><!--l. 972--></p>

<table id="tablepress-16" class="tablepress tablepress-id-16">
<thead>
<tr class="row-1 odd">
	<th class="column-1">Day</th><th class="column-2">Core-Hours Available</th><th class="column-3">Usage on this Day</th><th class="column-4">Core-Hours Used This Day</th>
</tr>
</thead>
<tbody class="row-hover">
<tr class="row-2 even">
	<td class="column-1">1</td><td class="column-2">43,200</td><td class="column-3">20 cores x 24 hours</td><td class="column-4">480</td>
</tr>
<tr class="row-3 odd">
	<td class="column-1">2</td><td class="column-2">42,720</td><td class="column-3">20 cores x 24 hours</td><td class="column-4">480</td>
</tr>
<tr class="row-4 even">
	<td class="column-1">3</td><td class="column-2">42,240</td><td class="column-3">20 cores x 24 hours</td><td class="column-4">480</td>
</tr>
<tr class="row-5 odd">
	<td class="column-1">4</td><td class="column-2">41,760</td><td class="column-3">20 cores x 24 hours</td><td class="column-4">480</td>
</tr>
</tbody>
</table>
<!-- #tablepress-16 from cache -->
<p class="indent">Usage continues at the same rate of 20 cores, 24 hours per day.</p>
<p><!--l. 982--></p>

<table id="tablepress-17" class="tablepress tablepress-id-17">
<thead>
<tr class="row-1 odd">
	<th class="column-1">Day</th><th class="column-2">Core-Hours Available</th><th class="column-3">Usage on this Day</th><th class="column-4">Core-Hours Used This Day</th>
</tr>
</thead>
<tbody class="row-hover">
<tr class="row-2 even">
	<td class="column-1">90</td><td class="column-2">480</td><td class="column-3">20 cores x 24 hours</td><td class="column-4">480</td>
</tr>
<tr class="row-3 odd">
	<td class="column-1">91</td><td class="column-2">480</td><td class="column-3">20 cores x 24 hours</td><td class="column-4">480</td>
</tr>
<tr class="row-4 even">
	<td class="column-1">92</td><td class="column-2">480</td><td class="column-3">20 cores x 24 hours</td><td class="column-4">480</td>
</tr>
</tbody>
</table>
<!-- #tablepress-17 from cache -->
<p class="indent">Note that on Day 91, the core-hours used on Day 1 become available again; on Day 92, the core-hours used on Day 2 become available again; and so on.<br />
<!--l. 984--></p>
<p class="indent"><span class="cmbx-10">Example: </span>Bursting above your allocation may lead to days with 0 hours available.</p>
<p><!--l. 995--></p>

<table id="tablepress-18" class="tablepress tablepress-id-18">
<thead>
<tr class="row-1 odd">
	<th class="column-1">Day</th><th class="column-2">Core-Hours Available</th><th class="column-3">Usage on this Day</th><th class="column-4">Core-Hours Used This Day</th>
</tr>
</thead>
<tbody class="row-hover">
<tr class="row-2 even">
	<td class="column-1">1</td><td class="column-2">43,200</td><td class="column-3">20 cores x 24 hours</td><td class="column-4">480</td>
</tr>
<tr class="row-3 odd">
	<td class="column-1">2</td><td class="column-2">42,720</td><td class="column-3">80 cores x 24 hours</td><td class="column-4">1920</td>
</tr>
<tr class="row-4 even">
	<td class="column-1">3</td><td class="column-2">40,800</td><td class="column-3">80 cores x 24 hours</td><td class="column-4">1920</td>
</tr>
<tr class="row-5 odd">
	<td class="column-1">4</td><td class="column-2">38,8801,760</td><td class="column-3">80 cores x 24 hours</td><td class="column-4">1920</td>
</tr>
</tbody>
</table>
<!-- #tablepress-18 from cache -->
<p class="indent">Usage continues at the same rate of 80 cores, 24 hours per day.</p>
<p><!--l. 1005--></p>

<table id="tablepress-19" class="tablepress tablepress-id-19">
<thead>
<tr class="row-1 odd">
	<th class="column-1">Day</th><th class="column-2">Core-Hours Available</th><th class="column-3">Usage on this Day</th><th class="column-4">Core-Hours Used This Day</th>
</tr>
</thead>
<tbody class="row-hover">
<tr class="row-2 even">
	<td class="column-1">24</td><td class="column-2">480</td><td class="column-3">60 cores x 8 hours</td><td class="column-4">480</td>
</tr>
<tr class="row-3 odd">
	<td class="column-1">25</td><td class="column-2">0</td><td class="column-3">0</td><td class="column-4">0</td>
</tr>
<tr class="row-4 even">
	<td class="column-1">26</td><td class="column-2">0</td><td class="column-3">0</td><td class="column-4">0</td>
</tr>
</tbody>
</table>
<!-- #tablepress-19 from cache -->
<p class="indent">At this point, no core-hours are available, and no jobs can be run against the allocation until Day 91, when the core-hours used on Day 1 become available again.</p>
<p><!--l. 1015--></p>

<table id="tablepress-20" class="tablepress tablepress-id-20">
<thead>
<tr class="row-1 odd">
	<th class="column-1">Day</th><th class="column-2">Core-Hours Available</th><th class="column-3">Usage on this Day</th><th class="column-4">Core-Hours Used This Day</th>
</tr>
</thead>
<tbody class="row-hover">
<tr class="row-2 even">
	<td class="column-1">91</td><td class="column-2">480</td><td class="column-3">20 cores x 24 hours</td><td class="column-4">480</td>
</tr>
<tr class="row-3 odd">
	<td class="column-1">92</td><td class="column-2">1920</td><td class="column-3">0</td><td class="column-4">0</td>
</tr>
<tr class="row-4 even">
	<td class="column-1">93</td><td class="column-2">3840</td><td class="column-3">20 cores x 24 hours</td><td class="column-4">480</td>
</tr>
</tbody>
</table>
<!-- #tablepress-20 from cache -->
<p class="indent"><span class="cmbx-10">Identifying Allocation Usage:</span><br />
<!--l. 1018--></p>
<p class="indent">Users are able to see their allocations with the balance using the command mam-list-funds. This is typically used with the -h flag to show the allocation and balance in hours.</p>
<pre>mam-list-funds -h</pre>
<p><!--l. 1021--></p>
<p class="nopar"><!--l. 1023--></p>
<p class="indent">The allocation topology, end date and node-type can be shown using the mam-list-accounts command.</p>
<pre>mam-list-accounts</pre>
<p><!--l. 1026--></p>
<p class="nopar">Note that this shows you expired allocations as well. The second column (Active) will show True for active allocations and False for expired allocations.<br />
<!--l. 1029--></p>
<p class="indent">Users interested in their own usage may want to investigate several of the other mam commands:</p>
<pre>mam-list-usagerecords
mam-list-transactions
</pre>




	<a name="07-05-aci-b-gpu-nodes"></a><br>
	<h4>7.5 ACI-b GPU nodes</h4>
	<p>The ACI-b GPU nodes are comprised of dual NVIDIA Tesla K80 GPU cards. Each card contains two GPUs that are individually schedulable. These nodes contain dual E5-2680 processors (24 total cores), and 256GB of RAM. For more information on this hardware, refer to <a class="reference external" href="https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/tesla-product-literature/Tesla-K80-BoardSpec-07317-001-v05.pdf">NVIDIA&#8217;s K80 specification document</a>.</p>
<h5><span class="titlemark">7.5.1</span> Accessing GPU Resources</h5>
<p>To access a GPU on ACI-b, you must be a member of a GReAT GPU allocation. To request a node with a GPU, add <em>“gpus=N”</em> to your resource list in either your job script or a submission argument. For example, <code>#PBS -l nodes=1:ppn=1:gpus=1</code> or <code>qsub -l nodes=1:ppn=1:gpus=1 ...</code><br />
The requested GPU is placed in exclusive process mode by default. This means that only a single process can access the GPU, but it can spawn multiple different threads. To allow multiple processes on a single GPU, the “shared” feature can be appended to the resource list. A general GPU request then takes the form of:<br />
<code>#PBS -l nodes=NN:ppn=NC:gpus=NG:feature</code><br />
or<br />
<code>qsub -l nodes=NN:ppn=NC:gpus=NG:feature</code><br />
Where:</p>
<ul>
<li>NN = the number of nodes</li>
<li>NC = the number of cores per node</li>
<li>NG = the number of GPUS per node</li>
<li>feature = shared or is not included</li>
</ul>
<p><strong>GPU job script example</strong><br />
Here is an example GPU job script that requests a single GPU and simply calls nvidia-smi:</p>
<pre class="script">#!/bin/bash
#PBS -l nodes=1:ppn=1:gpus=1
#PBS -l walltime=2:00
#PBS -l pmem=1gb
#PBS -A gpu_allocation_name

# Get started
echo " "
echo "Job started on `hostname` at `date`"
echo " "

# Go to the submission directory
cd $PBS_O_WORKDIR

# Run the main job commands
nvidia-smi

# Finish up
echo " "
echo "Job Ended at `date`"
</pre>
<h5><span class="titlemark">7.5.2</span> GPU Monitoring</h5>
<p>You may want to monitor the status of a node’s GPU. The nvidia-smi command provides basic monitoring capabilities and will provide information such as GPU and memory utilization, power consumption, running processes, etc. Example output for this command:</p>
<pre class="script">$ nvidia-smi
Mon Oct  8 15:03:53 2018
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 390.30                 Driver Version: 390.30                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla K80           Off  | 00000000:05:00.0 Off |                    0 |
| N/A   41C    P0    63W / 149W |      0MiB / 11441MiB |      0%   E. Process |
+-------------------------------+----------------------+----------------------+
|   1  Tesla K80           Off  | 00000000:06:00.0 Off |                    0 |
| N/A   36C    P0    71W / 149W |      0MiB / 11441MiB |      0%   E. Process |
+-------------------------------+----------------------+----------------------+
|   2  Tesla K80           Off  | 00000000:84:00.0 Off |                    0 |
| N/A   40C    P0    59W / 149W |      0MiB / 11441MiB |      0%   E. Process |
+-------------------------------+----------------------+----------------------+
|   3  Tesla K80           Off  | 00000000:85:00.0 Off |                    0 |
| N/A   32C    P0    75W / 149W |      0MiB / 11441MiB |     81%   E. Process |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
</pre>
<h5><span class="titlemark">7.5.3</span> CUDA</h5>
<p>NVIDIA has developed a parallel computing platform and programming model to facilitate the use of GPUs in general computing. This comes in the form of both GPU-accelerated libraries as well as programming extensions for C, C++, and Fortran (PGI compilers). CUDA 8.0, 9.0, and 9.1 are installed on the gpu nodes at /usr/local. To set up your shell environment, the CUDA bin and lib64 directories need to be added to PATH and LD_LIBRARY_PATH.<br />
<code>$ export PATH=/usr/local/cuda-9.1/bin:$PATH<br />
$ export LD_LIBRARY_PATH=/usr/local/cuda-9.1/lib64:$LD_LIBRARY_PATH<br />
</code><br />
<strong>CUDA example</strong><br />
The CUDA Toolkit includes many CUDA code examples that can help get you started with writing your own CUDA-enabled software. These examples can be found at /usr/local/cuda/samples/ for the latest available version of CUDA. You may also find <a title="CUDA code samples" href="https://developer.nvidia.com/cuda-code-samples">additional CUDA code samples</a> on the NVIDIA website.<br />
Here, we will compare the performance of the CPU and GPU for the &#8220;nbody&#8221; example.</p>
<ol>
<li>Start an interactive session on a GPU node<br />
<code class="oneline">$ qsub -I -A gpu_allocation_name -l nodes=1:ppn=1:gpus=1 -l pmem=10gb -l walltime=1:00:00</code></li>
<li>Set up the environment<br />
<code class="oneline">$ export PATH=/usr/local/cuda-9.1/bin:$PATH<br />
$ export LD_LIBRARY_PATH=/usr/local/cuda-9.1/lib64:$LD_LIBRARY_PATH<br />
$ export CPATH=/usr/local/cuda-9.1/samples/common/inc:$CPATH</code></li>
<li>Copy the nbody source code to your ACI work directory<br />
<code class="oneline">$ mkdir ~/work/cuda_example &amp;&amp; cd ~/work/cuda_example<br />
$ cp /usr/local/cuda-9.1/samples/5_Simulations/nbody/ .</code></li>
<li>Compile the nbody example<br />
<code class="oneline">$ cd nbody<br />
$ make</code></li>
<li>Compare GPU vs CPU timing<br />
<code class="oneline"><code class="oneline">CPU:<br />
$ ./nbody -benchmark -numbodies=1024 -cpu</code></code>GPU:<br />
$ ./nbody -benchmark -numbodies=1024 -numdevices=1</li>
</ol>
<p><strong>CUDA resources</strong></p>
<ul>
<li>XSEDE course: <a title="XSEDE course presentation" href="https://drive.google.com/file/d/12TwgVcVqoW8T9eyz7RuYQ9yw_si8kbA4/view">slides</a> and <a title="XSEDE course video" href="https://www.youtube.com/watch?v=2R5R0nXm3xc&amp;feature=youtu.be">video</a></li>
<li><a title="NVIDIA Education &amp; Training" href="https://developer.nvidia.com/cuda-education-training">NVIDIA Education &amp; Training</a></li>
<li><a title="Cornell University Virtual Workshop" href="https://cvw.cac.cornell.edu/GPU/default">Virtual Workshop</a></li>
</ul>
<h5><span class="titlemark">7.5.4</span> OpenACC</h5>
<p>OpenACC is an API comprised of compiler directives (similar to OpenMP) that enable programmers to specify portions of code (C, C++, and Fortran) to be executed on a GPU (or other accelerators). OpenACC compiler support will be available on the Roar systems with the release v18.5 of the PGI compilers. This section will be expanded once the PGI compilers are released.</p>
<h5><span class="titlemark">7.5.5</span> GPU Enabled Applications</h5>
<p>Some software packages available on the Roar software stack have native GPU support, as indicated in the table below. For a full description of available functionality, please consult each package’s software documentation.</p>
<p>
<table id="tablepress-29" class="tablepress tablepress-id-29">
<thead>
<tr class="row-1 odd">
	<th class="column-1">Software</th><th class="column-2">Information</th>
</tr>
</thead>
<tbody class="row-hover">
<tr class="row-2 even">
	<td class="column-1">Matlab</td><td class="column-2"><a href="https://mathworks.com/discovery/matlab-gpu.html" rel="noopener" target="_blank">MathWorks: Getting started with GPUs</a></td>
</tr>
<tr class="row-3 odd">
	<td class="column-1">Mathematica</td><td class="column-2"><a href="https://reference.wolfram.com/language/guide/GPUComputing.html" rel="noopener" target="_blank">Wolfram:  GPU computing</a></td>
</tr>
<tr class="row-4 even">
	<td class="column-1">Ansys: APDL</td><td class="column-2">ansys192 -acc nvidia -na N ...</td>
</tr>
<tr class="row-5 odd">
	<td class="column-1">Ansys: Fluent</td><td class="column-2">fluent -gpgpu=N ...</td>
</tr>
<tr class="row-6 even">
	<td class="column-1">Ansys: polyflow</td><td class="column-2">polyflow -acc nvidia -na N ...</td>
</tr>
<tr class="row-7 odd">
	<td class="column-1">Ansys: other</td><td class="column-2">The -batchoptions command flag can be used to enable GPU support. See the software specific manual available through the GUI for the options available for each Ansys product.<br />
<br />
ex. ansysedt -batchoptions “HFSS/EnableGPU=1” ...</td>
</tr>
<tr class="row-8 even">
	<td class="column-1">Abaqus</td><td class="column-2">abaqus gpus=N ... OR abaqus -gpus N ...</td>
</tr>
</tbody>
</table>
<!-- #tablepress-29 from cache --><br />
where N = the number of GPU devices</p>
<p><strong>Python TensorFlow example</strong><br />
TensorFlow is a popular open-source machine learning and deep learning library originally developed by Google. The API is typically used with Python, for which there is GPU support. The following example will walk through the local installation and testing of the GPU-enabled version of TensorFlow.</p>
<ol>
<li>Start an interactive session on a GPU node<br />
<code class="oneline">$ qsub -I -A gpu_allocation_name -l nodes=1:ppn=1:gpus=1 -l pmem=10gb -l walltime=1:00:00</code></li>
<li>Create a conda environment for tensorflow-gpu<br />
<code class="oneline">$ cd ~/work<br />
$ mkdir conda_gpu_tensorflow &amp;&amp; cd conda_gpu_tensorflow<br />
$ mkdir $PWD/conda_pkgs<br />
$ export CONDA_PKGS_DIRS=$PWD/conda_pkgs<br />
$ module load python/3.6.3-anaconda3<br />
$ conda create -y --prefix $PWD<br />
$ source activate $PWD</code><br />
(Use <code>source deactivate</code> to exit the conda environment.)</li>
<li>Install the cudatoolkit for python. The version of cudatoolkit must be compatible with the GPU driver version. The current driver (390.30) supports up to CUDA 9.1.<br />
<code class="oneline">$ conda install -y cudatoolkit=9.0</code></li>
<li>Install tensorflow-gpu. Note that the packaged binaries were not compiled with optimized instruction sets such as AVX, AVX2, etc. To compile your own version of tensorflow from source, see the official <a title="TensorFlow documentation" href="https://www.tensorflow.org/install/source">TensorFlow documentation</a>.<br />
<code class="oneline">$ conda install --no-update-dependencies -y tensorflow-gpu</code></li>
<li>Run the GPU test model. The average performance should be ~5,300 examples/sec for a single GPU.<br />
<code class="oneline">$ git clone https://github.com/tensorflow/models.git</code><br />
<code class="oneline">$ python models/tutorials/image/cifar10/cifar10_train.py</code></li>
</ol>




	<a name="08-00-running-jobs-on-hprc"></a><br>
	<h3>8 Running Jobs on HPRC</h3>
	<p>HPRC jobs are submitted from the head nodes of ACI-b and will run when available resources are available on the compute nodes. Roar uses Moab and Torque for the scheduler and resource manager. Jobs can be either run in batch or interactive modes. Both are submitted using the qsub command.</p>




	<a name="08-01-requesting-resources"></a><br>
	<h4>8.1 Requesting Resources</h4>
	<p>Whether you are submitting batch or interactive jobs, you are required to provide a list of requested resources to the scheduler. These are given either in the submission script or on the command line. If these are given in a submission script, they must come before any non-PBS command. Current limits on HPRC resource requests:<br />
• Pmem &lt; 8GB<br />
• Mem &lt; 160GB<br />
• Core/node &lt;= 20<br />
• Node = 1</p>




	<a name="08-012-sample-script"></a><br>
	<h4>8.1.1 Sample HPRC Batch Submission Script</h4>
	<p>The following is a submission script for a Matlab job that will run for 5 minutes on one processor. Note that an allocation is required to submit jobs to HPRC. Users familiar with submitting jobs to ACI-b will note only minor differences in this script.<br />
<code>#!/bin/bash<br />
#PBS -l nodes=1:ppn=1<br />
#PBS -l walltime=5:00<br />
#PBS -q hprc</code></p>
<p><code>#PBS -A ics-hprc<br />
# Get started<br />
echo "Job started on ‘hostname‘ at ‘date‘"<br />
# Load in matlab<br />
module purge<br />
module load matlab<br />
# Go to the correct place<br />
cd $PBS_O_WORKDIR<br />
# Run the job itself - a matlab script called runThis.m<br />
matlab-bin -nodisplay -nosplash &lt; runThis.m &gt; log.matlabRun<br />
# Finish up<br />
echo "Job Ended at ‘date‘"</code></p>




	<a name="08-02-interactive-compute-sessions-on-hprc"></a><br>
	<h4>8.2 Interactive Compute Sessions on HPRC</h4>
	<p>Interactive jobs may be submitted to HPRC using the -I (for interactive) flag. Interactive jobs require resource requests and an allocation. An interactive job can be submitted using a command similar to:</p>
<p><code>qsub -I -A ics-hprc -q hprc -l nodes=1:ppn=20 -l mem=32gb -l walltime=1:23:30:00</code></p>
<p>The job will be given a job ID, and your session will wait until this job has the resources to start. You will then be placed on the compute node and given a usable terminal session within your current session. For example, a user submitting an interactive job may see:</p>
<p><code>[abc123@aci-lgn-008 abc123]$ qsub -I -A ics-hprc -q hprc -l nodes=1:ppn=20 -l mem=32gb -l walltime=1:23:30:00<br />
qsub: waiting for job 12907285.torque01.util.production.int.aci.ics.psu.edu to start<br />
qsub: job 12907285.torque01.util.production.int.aci.ics.psu.edu ready<br />
[abc123@comp-vc-1645 abc123]$</code></p>
<p>To enable X11 forwarding to the interactive job, include the -x flag (output will be identical to above):</p>
<p><code>qsub -I -x -A ics-hprc -q hprc -l nodes=1:ppn=20 -l mem=32gb -l walltime=1:23:30:00</code></p>




	<a name="08-03-requesting-a-custom-singularity-container-on-hprc"></a><br>
	<h4>8.3 Requesting a Custom Singularity Container on HPRC</h4>
	<p>Jobs on HPRC are run in an enterprise Linux 6 container. If you want your job to run in a custom Singularity container, you can specify that container either on the qsub command line or within your script.</p>
<p>Here is an example on the qsub command line:</p>
<p><code>qsub -I -v SINGULARITY_CONTAINER="/storage/work/abc123/singularity/bionic-base.simg"</code></p>
<p>For example, the above interactive job would provide:</p>
<p><code>[abc123@aci-lgn-008 abc123]$ qsub -I -A ics-hprc -q hprc -l nodes=1:ppn=20 -l mem=32gb -l walltime=1:23:30:00<br />
qsub: waiting for job 12907285.torque01.util.production.int.aci.ics.psu.edu to start<br />
qsub: job 12907285.torque01.util.production.int.aci.ics.psu.edu ready<br />
[abc123@comp-vc-1645 abc123]$ cat /etc/os-release<br />
NAME="Ubuntu"<br />
VERSION="18.04.1 LTS (Bionic Beaver)"<br />
ID=ubuntu<br />
ID_LIKE=debian<br />
PRETTY_NAME="Ubuntu 18.04.1 LTS"<br />
VERSION_ID="18.04"<br />
HOME_URL="https://www.ubuntu.com/"<br />
SUPPORT_URL="https://help.ubuntu.com/"<br />
BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"<br />
PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"<br />
VERSION_CODENAME=bionic<br />
UBUNTU_CODENAME=bionic</code></p>
<p>Here is an example where the container is specified within your submission script:</p>
<p><code>#PBS -l walltime=1:30:00<br />
#PBS -l nodes=1:ppn=8<br />
#PBS -l mem=8gb<br />
#PBS -j oe<br />
#PBS -r n<br />
#PBS -m bae<br />
#PBS -M abf123@psu.edu<br />
#PBS -q hprc<br />
#PBS -A ics-hprc<br />
#PBS -v SINGULARITY_CONTAINER="/storage/work/abc123/singularity/bionic-base.simg"</code></p>




	<a name="08-04-specifying-a-custom-bash-environment-on-hprc"></a><br>
	<h4>8.4 Specifying a Custom Bash Environment on HPRC</h4>
	<p>Some jobs may be best served by custom bash environments, especially those run within containers that do not support modules or other environment variables supported on ACI-b directly. A custom bash environment can be specified with a qsub variable on the command line or within your submission script.</p>
<p>Here’s an example on the command line:</p>
<p><code>qsub -I -v SINGULARITY_CONTAINER="/storage/work/abc123/singularity/bionic-base.simg" -v BASH_ENV=”/storage/abc123/.bashrc_ubuntu” -q hprc -A epo2-hprc -l nodes=1:ppn=20 -l pmem=5gb -l walltime=16:30:00</code></p>
<p>Here’s an example within the submission script:</p>
<p><code>#PBS -l walltime=1:30:00<br />
#PBS -l nodes=1:ppn=8<br />
#PBS -l mem=8gb<br />
#PBS -j oe<br />
#PBS -r n<br />
#PBS -m bae<br />
#PBS -M abf123@psu.edu<br />
#PBS -q hprc<br />
#PBS -A ics-hprc<br />
#PBS -v SINGULARITY_CONTAINER="/storage/work/abc123/singularity/bionic-base.simg"<br />
#PBS -v BASH_ENV=”/storage/abc123/.bashrc_ubuntu”</code></p>




	<a name="09-00-software-stack"></a><br>
	<h3>9 Software Stack</h3>
	<p class="noindent">ICDS has a software policy that explains the details of how software can be used. The policy can be read on <a href="https://www.icds.psu.edu/computing-services/ics-aci-policies/">our policy page</a>.<br />
<!--l. 1040--></p>




	<a name="09-01-user-stack"></a><br>
	<h4>9.1 User Stack</h4>
	<p><!--l. 1041--></p>
<p class="noindent">Users are able to install software into their own home and work directories as well as in group spaces. ICDS strongly recommends that research groups who compute in multiple locations do this for all of their software so that the version can be consistent across platforms.<br />
<!--l. 1043--></p>
<p class="indent">The i-ASK Center can provide guidance for the installation of many software packages.<br />
<!--l. 1045--></p>




	<a name="09-02-system-stack"></a><br>
	<h4>9.2 System Stack</h4>
	<p><!--l. 1049--></p>
<p class="noindent">Many commonly used applications are built and maintained by the system.<br />
<!--l. 1051--></p>
<h5 class="subsubsectionHead"><span class="titlemark">9.2.1 </span> <a id="x1-580008.2.1"></a>System Stack Requests</h5>
<p><!--l. 1052--></p>
<p class="noindent">Requests for software to be placed on the system stack can be made to the i-ASK Center. Users requesting software should show the reason for the request, typically due to licensing issues or because of the broad user base across campus.<br />
<!--l. 1054--></p>




	<a name="09-03-system-stack-applications"></a><br>
	<h4>9.3 System Stack Applications</h4>
	<p><!--l. 1055--></p>
<p class="noindent">Because of the module families, it is hard to view all of the available software on the system. The software list can be found on the <a href="https://www.icds.psu.edu/computing-services/software/">software stack webpage</a> or by looking in the directory where the software modules are:</p>
<pre>ls /opt/aci/sw/</pre>
<p><!--l. 1058--></p>
<p class="nopar"><!--l. 1060--></p>
<p><!--l. 1071--></p>
<h5 class="subsubsectionHead"><span class="titlemark">9.3.1 </span> <a id="x1-600008.3.1"></a>COMSOL</h5>
<p><!--l. 1073--></p>
<p class="noindent">To open COMSOL, first log into ACI-i using Open OnDemand. More information regarding how to do this can be found in <a href="https://www.icds.psu.edu/computing-services/ics-aci-user-guide/#05-04-connecting-aci">section 5.4.1</a>. Next open a terminal by going to the top left corner and clicking on</p>
<pre>Applications -&gt; System Tools -&gt; Terminal</pre>
<p><!--l. 1077--></p>
<p class="nopar"><!--l. 1079--></p>
<p class="indent">In the terminal window type the following commands:</p>
<pre>module load comsol
comsol
</pre>
<p><!--l. 1083--></p>
<p class="nopar"><!--l. 1085--></p>
<p class="indent">The graphical user interface for COMSOL should now be opened and COMSOL can be used as usual. However, it is worth mentioning that ACI-i is only intended to run short jobs. Often researchers will use ACI-i to develop and test their COMSOL models before submitting them as jobs on the more computational powerful ACI-b cluster. Running a COMSOL model on the ACI-b system is a relatively straightforward process. To do so, first create your model (often done using the GUI in ACI-i). Next log into ACI-b, and submit your job to the scheduler. For information on submitting a job to ACI-b, see <a href="https://www.icds.psu.edu/computing-services/ics-aci-user-guide/#07-00-running-jobs-on-aci-b">section 7</a>.<br />
<!--l. 1089--></p>
<p class="indent">An example of a PBS script to submit a COMSOL job:</p>
<pre class="script">#!/bin/bash

#PBS -l nodes=1:ppn=4

#PBS -l walltime=12:00:00

#PBS -A open

#PBS -o ComsolPBS.output

#PBS -e ComsolPBS.error

#PBS -m abe

#PBS -M abc1234@psu.edu

#PBS -n myComsolJob

# Get started

echo " "

echo "Job started on ‘hostname‘ at ‘date‘"

echo " "

# Load in Comsol

module purge

module load comsol

# Go to the correct place

cd $PBS_O_WORKDIR

# Run the job itself

comsol batch -inputfile inputFile.mph -outputfile /path/to/output/outputFileName.mph -batchlog log.txt

# Finish up

echo " "

echo "Job Ended at ‘date‘"

echo " "

</pre>
<p><!--l. 1116--></p>
<p class="nopar"><!--l. 1118--></p>
<p class="indent">More information on options used for submitting comsol jobs using the command line can be found by typing the commands:</p>
<pre>module load comsol
comsol -h
</pre>
<p><!--l. 1122--></p>
<p class="nopar"><!--l. 1124--></p>
<h5 class="subsubsectionHead"><span class="titlemark">9.3.2 </span> <a id="x1-610008.3.2"></a>Julia</h5>
<p><!--l. 1126--></p>
<p class="noindent">Julia is a high-level, high-performance dynamic programming language for numerical computing. It provides a sophisticated compiler, distributed parallel execution, numerical accuracy, and an extensive mathematical function library. Julia&#8217;s Base library, largely written in Julia itself, also integrates mature, best-of-breed open source C and Fortran libraries for linear algebra, random number generation, signal processing, and string processing.<br />
<!--l. 1132--></p>
<p class="indent">The system Julia module is compiled with the GCC compiler. Using Julia requires the gcc module to be loaded:</p>
<pre>$ module load gcc
$ module load julia
$ julia
</pre>
<p><!--l. 1137--></p>
<p class="nopar"><!--l. 1139--></p>
<p class="indent">Example Julia Code:</p>
<pre class="script">Pkg.add("Winston")

using Winston

# optionally call figure prior to plotting to set the size

figure(width=600, height=400)

# plot some data

pl = plot(cumsum(rand(500) .- 0.5), "r", cumsum(rand(500) .- 0.5), "b")

# display the plot (not done automatically!)

display(pl)

# by default display will not wait and the plot will vanish as soon as it appears

# using readline is a blunt wait to allow the user to choose when to continue

# println("Press enter to continue: ")

# readline(STDIN)

# save the current figure

savefig("winston.svg")

# .eps, .pdf, &amp; .png are also supported

# we used svg here because it respects the width and height specified above

</pre>
<p><!--l. 1162--></p>
<p class="nopar"><!--l. 1164--></p>
<p class="indent">An example PBS submission script for a julia simulation can be found:</p>
<pre class="script">#!/bin/bash

#PBS -l procs=1

#PBS -l walltime=240:00:00

#PBS -l pmem=1000mb

#PBS -n jobName

#PBS -m ea

#PBS -M PSU1234@psu.edu

#PBS -j oe

# Get started

echo " "

echo "Job started on ‘hostname‘ at ‘date‘"echo " "

module load gcc

module load julia

cd $PBS_O_WORKDIR

julia jobName.ji

# Finish up

echo " "

echo "Job Ended at ‘date‘"

echo " "

</pre>
<p><!--l. 1190--></p>
<p class="nopar"><!--l. 1192--></p>
<h5 class="subsubsectionHead"><span class="titlemark">9.3.3 </span> <a id="x1-620008.3.3"></a>Matlab</h5>
<p><!--l. 1194--></p>
<p class="noindent">Matlab is a widely used programming environment and language. The GUI can be accessed on ACI-i using the following commands:</p>
<pre>module load matlab
matlab
</pre>
<p><!--l. 1198--></p>
<p class="nopar"><!--l. 1200--></p>
<p class="indent">Matlab can also be run in batch mode, either on the command line or submitted as a job. Jobs run in batch mode must have an *.m file. An example that writes a random matrix as a .csv file:</p>
<pre class="script">%This Matlab script makes a random matrix and outputs a csv file of it.

%This was made as a simple example to demostrate how to submit batch Matlab

%codes

%Created by i-ASK at ICDS of Penn State

% June 27, 2017

%% Create Random Matrix

RandomMatrix = rand(5);

%% Export csv file

csvwrite(’output.csv’,RandomMatrix)

</pre>
<p><!--l. 1215--></p>
<p class="nopar">This can be saved as Example.m and submitted to ACI-b using the following submission script:</p>
<pre class="script">#!/bin/bash

#PBS -S /bin/bash

#PBS -l nodes=1:ppn=1,walltime=00:05:00

#PBS -N MyJobName

#PBS -e error.txt

#PBS -o output.txt

#PBS -j oe

#PBS -A open

#PBS -m abe

#PBS -M abc1234@psu.edu

# Get started

echo " "

echo "Job started on ‘hostname‘ at ‘date‘"

echo " "

# Load in matlab

module purge

module load matlab

# Run the job itself

matlab -nodisplay -nosplash -r Example &gt; logfile.matlabExample

# Finish up

echo " "

echo "Job Ended at ‘date‘"

echo " "

</pre>
<p><!--l. 1245--></p>
<p class="nopar"><!--l. 1248--></p>
<p class="indent">For more information about Matlab, please refer to the <a href="https://www.mathworks.com/products/matlab.html">Matlab website</a>.<br />
<!--l. 1250--></p>
<h5 class="subsubsectionHead"><span class="titlemark">9.3.4 </span> <a id="x1-630008.3.4"></a>Mathematica</h5>
<p><!--l. 1252--></p>
<p class="noindent">Mathematica builds in unprecedentedly powerful algorithms across all areas many of them created at Wolfram using unique development methodologies and the unique capabilities of the Wolfram Alpha. Mathematica is built to provide industrial-strength capabilities with robust, efficient algorithms across all areas, capable of handling large-scale problems, with parallelism, GPU computing, and more . Mathematica provides a progressively higher-level environment in which as much as possible is automated so you can work as efficiently as possible.<br />
<!--l. 1254--></p>
<p class="indent">The Mathematica module can be loaded with the command</p>
<pre>module load mathematica</pre>
<p><!--l. 1257--></p>
<p class="nopar"><!--l. 1259--></p>
<p class="indent">A sample Mathematica code for printing random numbers into a text file:</p>
<pre class="script">Accumulate[RandomReal[{-1, 1}, 1000]]&gt;&gt;"output.txt"

Quit [ ]

</pre>
<p><!--l. 1263--></p>
<p class="nopar"><!--l. 1265--></p>
<p class="indent">More examples of Mathematica code can be found <a href="https://www.wolfram.com/language/gallery/">here.</a></p>
<p class="indent">Sample Shell script for Batch System</p>
<pre class="script">#!/bin/bash

#PBS -N jobname

#PBS -l nodes=1:ppn= 1

#PBS -l mem=2gb,walltime=00:10:00

#PBS -A open

#PBS -o samplePBS.output

#PBS -e samplePBS.error

# Get started

echo " "

echo "Job started on ‘hostname‘ at ‘date‘"

echo " "

# Load in Mathematica

module purge

module load mathematica

# Go to the correct place

cd $PBS_O_WORKDIR

# Run the job itself

math -noprompt -run ’&lt;&lt;samplecode.nb’

# Finish up

echo " "

echo "Job Ended at ‘date‘"

echo " "

</pre>
<p><!--l. 1296--></p>
<p class="nopar"><!--l. 1298--></p>
<p class="indent">An additional PBS submission script sample for Mathematica is given here:</p>
<pre class="script">#!/bin/bash

#PBS -l nodes=1:ppn=1

#PBS -l walltime=5:00

#PBS -A open

#PBS -o MathematicaPBS.output

#PBS -e MathematicaPBS.error

# Get started

echo " "

echo "Job started on ‘hostname‘ at ‘date‘"

echo " "

# Load in Mathematica

module purge

module load mathematica

# Go to the correct place

cd $PBS_O_WORKDIR

# Run the job itself

math -noprompt -run ’&lt;&lt;input.m’

# Finish up

echo " "

echo "Job Ended at ‘date‘"

echo "

</pre>
<p><!--l. 1327--></p>
<p class="nopar"><!--l. 1332--></p>
<h5 class="subsubsectionHead"><span class="titlemark">9.3.5 </span> <a id="x1-640008.3.5"></a>Stata</h5>
<p><!--l. 1334--></p>
<p class="noindent">Stata is a powerful statistical package with smart data-management facilities, a wide array of up-to-date statistical techniques, and an excellent system for producing publication-quality graphs. It is widely used by many businesses and academic institutions especially in the fields of economics, sociology, political science, biomedicine and epidemiology. Stata is available for Windows, Linux/Unix, and Mac computers. There are four versions of Stata as follows:</p>
<ul class="itemize1">
<li class="itemize">Stata/MP for multiprocessor computers (including dual-core and multicore processors). Stata/MP is licensed based on the maximum number of cores than an individual job can use. RCC licenses Stata/MP16, which can run on up to 16 cores.</li>
<li class="itemize">Stata/SE for large databases</li>
<li class="itemize">Stata/IC which is the standard version</li>
<li class="itemize">Small Stata which is a smaller, student version of educational purchase only.</li>
</ul>
<p><!--l. 1345--></p>
<p class="indent">For parallel processing in Stata you must use stata-mp at the bottom of your PBS script. You must also indicate the number of processors (up to 16) in the PBS script as well as your do file. As a line in your do file be sure to include ”set processors n”, where n = the number of processors and should be the same as the number in your PBS script. An example PBS script is below where the number of processors is set to 8.<br />
<!--l. 1349--></p>
<p class="indent"><span class="cmbx-10">Setup:</span><br />
<!--l. 1351--></p>
<p class="indent">In Linux, load the module with the following command before you start working with Stata:</p>
<pre>module load stata</pre>
<p><!--l. 1354--></p>
<p class="nopar"><!--l. 1356--></p>
<p class="indent">Note that this command will load the current version. Other available versions can be checked by following command:</p>
<pre>module avail stata</pre>
<p><!--l. 1359--></p>
<p class="nopar"><!--l. 1361--></p>
<p class="indent"><span class="cmbx-10">Usage </span>To start Stata , type:</p>
<pre>stata-mp</pre>
<p><!--l. 1365--></p>
<p class="nopar"><!--l. 1367--></p>
<p class="indent">Use only ACI-i for interactive jobs. If you are remotely connecting to our systems via Open OnDemand, we recommend using the GUI version of Stata:</p>
<pre>xstata-mp</pre>
<p><!--l. 1370--></p>
<p class="nopar"><!--l. 1372--></p>
<p class="indent">Batch usage: Sample PBS script is given below:</p>
<pre class="script">#!/bin/bash

#PBS -l nodes=1:ppn=1

#PBS -l walltime=00:15:00

#PBS -A open

#PBS -n jobName

#PBS -M user123@psu.edu

#PBS -m abe

#PBS -j oe

# Get started

echo " "

echo "Job started on ‘hostname‘ at ‘date‘"

echo " "

# Load in Stata

module purge

module load stata

# Go to the correct place

cd $PBS_O_WORKDIR

# Run the job itself

stata -b do filename

# Finish up

echo " "

echo "Job Ended at ‘date‘"

echo " "

</pre>
<p><!--l. 1402--></p>
<p class="nopar"><!--l. 1404--></p>
<p class="indent">You can use stata-mp by substituting the stata command with the following:</p>
<pre>stata-mp -b do jobName.do</pre>
<p><!--l. 1407--></p>
<p class="nopar"><!--l. 1410--></p>
<h5 class="subsubsectionHead"><span class="titlemark">9.3.6 </span> <a id="x1-650008.3.6"></a>Python</h5>
<p><!--l. 1412--></p>
<p class="noindent">Python is a multi-use programming language used in a wide variety of fields. It can be run in batch mode on ACI-i or used in submitted jobs on ACI-b.<br />
<!--l. 1414--></p>
<p class="indent">An example python script, named jobName.py:</p>
<pre class="script">import sys

jobName = [Hello, World]

for i in jobName:

print i

sys.exit(0)

#end of jobName.py

</pre>
<p><!--l. 1422--></p>
<p class="nopar"><!--l. 1424--></p>
<p class="indent">This script can be submitted as a job on ACI-b with the following script:</p>
<pre class="script">#!/bin/bash -l

#PBS N jobName

#PBS l nodes=1:ppn=12

#PBS l walltime=00:05:00

#PBS j oe

#PBS -M abc123@psu.edu

# Get started

echo " "

echo "Job started on ‘hostname‘ at ‘date‘"

echo " "

#load in python

module purge

module load python/2.7.1

#go to the correct work directory

cd $PBS_O_WORKDIR

python jobName.py

# Finish up

echo " "

echo "Job Ended at ‘date‘"

echo " "

</pre>
<p><!--l. 1450--></p>
<p class="nopar"><!--l. 1452--></p>
<p class="indent">For more information, please feel free to refer to the <a href="https://www.python.org/">Python website</a>.<br />
<!--l. 1454--></p>
<p class="indent">An excellent resource for various plotting methods found within python can be found at the <a href="https://matplotlib.org/gallery.html">matplotlib gallery.</a></p>
<p>&nbsp;</p>
<h5 class="subsubsectionHead"><span class="titlemark">9.3.7</span> Singularity</h5>
<p>Singularity is a <em>container</em> system developed for use on high-performance computing clusters. Container computing allows the creation of a virtual-machine-like environment, which gives the user access to different configurations of software for use on clusters.</p>
<p>Using Singularity to install a container on Roar can help users:</p>
<ul>
<li>avoid dependence challenges</li>
<li>perform the same expected behavior on local and remote systems</li>
<li>easily move containers to new locations</li>
</ul>
<p>This may help if you need to run a container without having sudo access, but keep in mind that the container must integrate seamlessly into the existing destination infrastructure.</p>
<p><em>8.3.7.1 Getting Started with Using Singularity</em></p>
<p>Before getting started with using Singularity on Roar, you will need to install Singularity on a system for which you have root access. <a href="https://www.sylabs.io/docs/">Singularity&#8217;s official user guide</a> provides instructions for doing this. Roar uses version 2.6.0 of Singularity.</p>
<p>You may also obtain help in ACI-b like so:</p>
<pre class="script">[cjb47@comp-sc-0157 ~]$ singularity help
USAGE: singularity [global options...] <command></command> [command options...] ...
GLOBAL OPTIONS:
-d|--debug Print debugging information
-h|--help Display usage summary
-s|--silent Only print errors
-q|--quiet Suppress all normal output
--version Show application version
-v|--verbose Increase verbosity +1
-x|--sh-debug Print shell wrapper debugging information
GENERAL COMMANDS:
help Show additional help for a command or container
selftest Run some self tests for singularity install
CONTAINER USAGE COMMANDS:
exec Execute a command within container
run Launch a runscript within container
shell Run a Bourne shell within container
test Launch a testscript within container
CONTAINER MANAGEMENT COMMANDS:
apps List available apps within a container
bootstrap *Deprecated* use build instead
build Build a new Singularity container
check Perform container lint checks
inspect Display container's metadata
mount Mount a Singularity container image
pull Pull a Singularity/Docker container to $PWD
COMMAND GROUPS:
image Container image command group
instance Persistent instance command group
CONTAINER USAGE OPTIONS:
see singularity help <command></command>
For any additional help or support visit the Singularity
website: https://www.sylabs.io</pre>
<p><em>9.3.7.2 Images supported</em></p>
<p>Singularity supports many types of containers, which are also known as images. These include:</p>

<table id="tablepress-30" class="tablepress tablepress-id-30">
<thead>
<tr class="row-1 odd">
	<th class="column-1">Image Type</th><th class="column-2">Description</th>
</tr>
</thead>
<tbody class="row-hover">
<tr class="row-2 even">
	<td class="column-1">simg</td><td class="column-2">standard image</td>
</tr>
<tr class="row-3 odd">
	<td class="column-1">directory</td><td class="column-2">Unix Directory containing root container image</td>
</tr>
<tr class="row-4 even">
	<td class="column-1">tar.gz</td><td class="column-2">Gzip compressed tar archive</td>
</tr>
<tr class="row-5 odd">
	<td class="column-1">tar.bx2</td><td class="column-2">Bzip2 compressed tar archive</td>
</tr>
<tr class="row-6 even">
	<td class="column-1">tar</td><td class="column-2">uncompressed tar archive</td>
</tr>
<tr class="row-7 odd">
	<td class="column-1">cpio.gz</td><td class="column-2">Gzip compressed CPIO archive</td>
</tr>
<tr class="row-8 even">
	<td class="column-1">cpio</td><td class="column-2">Uncompressed CPIO archive</td>
</tr>
</tbody>
</table>
<!-- #tablepress-30 from cache -->
<p>Standard image and directory are the most commonly used formats. The others tend to be archive of the directory format that are decompressed on the fly.</p>
<p><em>Note: Docker Integration</em><br />
Singularity supports Docker natively and directly. This means that nearly all Docker images can be used directly as long as the required functionality does not require root access; however, most applications do not require this. We provide an example in the next section, Obtaining pre-built images.</p>
<p><em>9.3.7.3 Obtaining Pre-built Images</em></p>
<p>Images built by others users, sometimes the developers of the desired software itself, are among the best choices for a base image and, in many cases, may be all a researcher needs to do to have an image that gives the desired outcome.</p>
<p>Here is a common-example, the Docker image, lolcow.</p>
<pre class="script">[cjb47@comp-sc-0161 ~]$ singularity run docker://godlovedc/lolcow
** NOTE: Singularity is in a testing phase on ACI-b and is currently unsupported.
Docker image path: index.docker.io/godlovedc/lolcow:latest
Cache folder set to /storage/home/c/cjb47/.singularity/docker
[1/1] |===================================| 100.0%
Creating container runtime...
Exploding layer:
˓→sha256:9fb6c798fa41e509b58bccc5c29654c3ff4648b608f5daa67c1aab6a7d02c118.tar.gz
Exploding layer:
˓→sha256:3b61febd4aefe982e0cb9c696d415137384d1a01052b50a85aae46439e15e49a.tar.gz
Exploding layer:
˓→sha256:9d99b9777eb02b8943c0e72d7a7baec5c782f8fd976825c9d3fb48b3101aacc2.tar.gz
Exploding layer:
˓→sha256:d010c8cf75d7eb5d2504d5ffa0d19696e8d745a457dd8d28ec6dd41d3763617e.tar.gz
Exploding layer:
˓→sha256:7fac07fb303e0589b9c23e6f49d5dc1ff9d6f3c8c88cabe768b430bdb47f03a9.tar.gz
Exploding layer:
˓→sha256:8e860504ff1ee5dc7953672d128ce1e4aa4d8e3716eb39fe710b849c64b20945.tar.gz
Exploding layer:
˓→sha256:736a219344fbca3099ce5bd1d2dbfea74b22b830bac0e85ecca812c2983390cd.tar.gz
WARNING: Non existent bind point (directory) in container: '/storage/home'
WARNING: Non existent bind point (directory) in container: '/storage/work'
WARNING: Non existent bind point (directory) in container: '/gpfs/scratch'
WARNING: Non existent bind point (directory) in container: '/gpfs/group'
WARNING: Non existent bind point (directory) in container: '/var/spool/torque'
WARNING: Could not chdir to home: /storage/home/cjb47
________________________________________
/ Tonight you will pay the wages of sin; \
\ Don't forget to leave a tip. /
----------------------------------------
\   ^__^
\   (oo)\_______
    (__)\       )\/\
        ||----w |
        ||     ||
</pre>
<p>This example presents problems in certain cases, because the image does not have access to the data on the Roar system:</p>
<pre class="script">[cjb47@comp-sc-0185 singularity]$ singularity shell docker://godlovedc/lolcow
** NOTE: Singularity is in a testing phase on ACI-b and is currently unsupported.
Docker image path: index.docker.io/godlovedc/lolcow:latest
Cache folder set to /storage/home/c/cjb47/.singularity/docker
Creating container runtime...
Exploding layer:
˓→sha256:9fb6c798fa41e509b58bccc5c29654c3ff4648b608f5daa67c1aab6a7d02c118.tar.gz
Exploding layer:
˓→sha256:3b61febd4aefe982e0cb9c696d415137384d1a01052b50a85aae46439e15e49a.tar.gz
Exploding layer:
˓→sha256:9d99b9777eb02b8943c0e72d7a7baec5c782f8fd976825c9d3fb48b3101aacc2.tar.gz
Exploding layer:
˓→sha256:d010c8cf75d7eb5d2504d5ffa0d19696e8d745a457dd8d28ec6dd41d3763617e.tar.gz
Exploding layer:
˓→sha256:7fac07fb303e0589b9c23e6f49d5dc1ff9d6f3c8c88cabe768b430bdb47f03a9.tar.gz
Exploding layer:
˓→sha256:8e860504ff1ee5dc7953672d128ce1e4aa4d8e3716eb39fe710b849c64b20945.tar.gz
Exploding layer:
˓→sha256:736a219344fbca3099ce5bd1d2dbfea74b22b830bac0e85ecca812c2983390cd.tar.gz
WARNING: Non existent bind point (directory) in container: '/storage/home'
WARNING: Non existent bind point (directory) in container: '/storage/work'
WARNING: Non existent bind point (directory) in container: '/gpfs/scratch'
WARNING: Non existent bind point (directory) in container: '/gpfs/group'
WARNING: Non existent bind point (directory) in container: '/var/spool/torque'
WARNING: Could not chdir to home: /storage/home/cjb47
Singularity: Invoking an interactive shell within container...
Singularity lolcow:/&gt; cd ~
bash: cd: /storage/home/cjb47: No such file or directory
</pre>
<p>We can note the first issue, the non-existent bind paths. For this type of image, add the bind paths by slightly modifying the images. This can be done by writing a simple set of instructions, which are used to create an image. This set of instructions is called a recipe, in Singularity terminology.</p>
<p><em>9.3.7.4 Handling the Bind Paths on Roar</em></p>
<p>In order to handle the bind paths, it is very helpful to start with a recipe to set the data paths, even if the image is mostly a prepared image from another source. We will take a look at how to do this, and then discuss the building process in more detail.</p>
<p>We can also start with a recipe and add the correct binding paths for ACI-b. Here is a simple example to handle the bind points using the lolcow image.</p>
<pre class="script">BOOTSTRAP: docker
FROM: godlovedc/lolcow
%post
#ACI mappings so you can access your files.
mkdir -p /storage/home
mkdir -p /storage/work
mkdir -p /gpfs/group
mkdir -p /gpfs/scratch
mkdir -p /var/spool/torque
</pre>
<p>We build the image in an environment where we have sudo access (not Roar):</p>
<pre class="script">[cjb47@localhost simple_bind]$ sudo singularity build ./lolcow.simg ./lolcow.recipe
Building into existing container: ./lolcow.simg
Using container recipe deffile: ./lolcow.recipe
Sanitizing environment
Adding base Singularity environment to container
Running post scriptlet
+ mkdir -p /storage/home
+ mkdir -p /storage/work
+ mkdir -p /gpfs/group
+ mkdir -p /gpfs/scratch
+ mkdir -p /var/spool/torque
Found an existing definition file
Adding a bootstrap_history directory
Finalizing Singularity container
Calculating final size for metadata...
Skipping checks
Building Singularity image...
Singularity container built: ./lolcow.simg
Cleaning up...
</pre>
<p>Next, transfer the image to Roar using scp, and run it:</p>
<pre class="script">[cjb47@comp-sc-0185 images]$ singularity run ./lolcow.simg
** NOTE: Singularity is in a testing phase on ACI-b and is currently unsupported.
_________________________________________
/ The Priest's grey nimbus in a niche \
| where he dressed discreetly. I will not |
| sleep here tonight. Home also I cannot |
| go. |
| |
| A voice, sweetened and sustained, |
| called to him from the sea. Turning the |
| curve he waved his hand. A sleek brown |
| head, a seal's, far out on the water, |
| round. Usurper. |
| |
\ -- James Joyce, "Ulysses" /
-----------------------------------------
\   ^__^
\   (oo)\_______
    (__)\       )\/\
        ||----w |
        ||     ||
</pre>
<p>Note that we are now able to access our data on the local Roar locations.</p>
<pre class="script">[cjb47@comp-sc-0185 images]$ singularity shell ./lolcow.simg
** NOTE: Singularity is in a testing phase on ACI-b and is currently unsupported.
Singularity: Invoking an interactive shell within container...
Singularity lolcow.simg:/gpfs/group/dml129/default/cjb47/singularity/images&gt; cd ~
Singularity lolcow.simg:~&gt; pwd
/storage/home/cjb47
</pre>
<h5>9.3.7.5 Ways of using Singularity containers</h5>
<p>Once a container has been built and is placed on Roar, you can use it in a variety of ways. Here, we explain a few ways, including:</p>
<ul>
<li>ACI-b interactive sessions</li>
<li>ACI-n batch sessions</li>
<li>Interactive shells</li>
<li>Executing commands</li>
<li>Running a container</li>
<li>Working with files</li>
</ul>
<p><em>ACI-b Interactive Sessions:</em></p>
<p>You can start an interactive sessions with X-forwarding using the following command:</p>
<p>(script: qsub -l walltime=04:00:00 -l nodes=1:ppn=4 -A open -I -X)O</p>
<p><strong>Warning:</strong> Do not run interactive sessions on the log-in (head) nodes. These nodes are shared among all users and can quickly be rendered unusable by computationally intensive jobs on the sessions. Use of the head nodes to perform computationally demanding tasks can lead to the programs being terminated, or deactivation of the user’s access to Roar.</p>
<p><em>ACI-b Batch Sessions:</em></p>
<p>Here are a few examples that will run an application or command non-interactively in a PBS job file.</p>
<pre class="script">#!/bin/bash
#PBS -N Lammps-singularity
#PBS -A open
#PBS -l walltime=04:00:00
#PBS -l nodes=2:ppn=20
#PBS -j oe
module load gcc/5.3.1 mpich/3.2
cd $PBS_O_WORKDIR
mpirun --hostfile $PBS_NODEFILE --np 40 singularity run /path/to/lammps_mpi.simg   in.
˓→friction \
&gt; out.friction
</pre>
<p><em>Interactive Shells:</em></p>
<p>If you need to use many interactive tools or applications, you may want to start an interactive shell. Use the following command to do this:</p>
<pre class="script">[cjb47@comp-bc-0226 images]$ cat /etc/issue
Red Hat Enterprise Linux Server release 6.10 (Santiago)
Kernel \r on an \m
[cjb47@comp-bc-0226 images]$ singularity shell ubuntu_aci.simg
** NOTE: Singularity is in a testing phase on ACI-b and is currently unsupported.
Singularity: Invoking an interactive shell within container...
Singularity ubuntu_aci.simg:/gpfs/group/dml129/default/cjb47/singularity/images&gt; cat /
˓→etc/issue
Ubuntu 16.04.5 LTS \n \l
</pre>
<p>You will be able to interact with directories that have been bound.</p>
<p><em>Executing Commands:</em></p>
<p>In some cases, you may only want to run a single command from within the container. The following is an example of this:</p>
<pre class="script">[cjb47@comp-bc-0226 images]$ R
R version 3.5.0 (2018-04-23) -- "Joy in Playing"
Copyright (C) 2018 The R Foundation for Statistical Computing
Platform: x86_64-redhat-linux-gnu (64-bit)
R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.
R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.
Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.
&gt; q()
Save workspace image? [y/n/c]: n
[cjb47@comp-bc-0226 images]$ singularity run shub://jekriske/r-base:3.4.4 R
** NOTE: Singularity is in a testing phase on ACI-b and is currently unsupported.
Progress |===================================| 100.0%
WARNING: Non existent mountpoint (directory) in container: '/var/singularity/mnt/
˓→final/storage/home'
WARNING: Non existent mountpoint (directory) in container: '/var/singularity/mnt/
˓→final/storage/work'
WARNING: Non existent mountpoint (directory) in container: '/var/singularity/mnt/
˓→final/gpfs/scratch'
WARNING: Non existent mountpoint (directory) in container: '/var/singularity/mnt/
˓→final/gpfs/group'
WARNING: Non existent mountpoint (directory) in container: '/var/singularity/mnt/
˓→final/var/spool/torque'
WARNING: Could not chdir to home: /storage/home/cjb47
ARGUMENT 'R' __ignored__
R version 3.4.4 (2018-03-15) -- "Someone to Lean On"
Copyright (C) 2018 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)
R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.
Natural language support but running in an English locale
R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.
Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.
&gt; q()
Save workspace image? [y/n/c]: n
</pre>
<p><em>Running a Container:</em></p>
<p>Some containers may have one or more runscripts, which allow a user to define a set of actions a container will run when it is called. For example:</p>
<pre class="script">[cjb47@comp-bc-0226 images]$ singularity run ./hello-world-aci.simg
** NOTE: Singularity is in a testing phase on ACI-b and is currently unsupported.
Hello there cjb47, from ICDS
</pre>
<p>A container may have multiple runscripts; in Singularity terminology, this is known as an &#8220;application.&#8221; Here is an example, including instructions for interacting with applications:</p>
<pre class="script">[cjb47@comp-sc-0120 images]$ singularity apps ./multiapps-aci.simg
cowsay
fortune
lolcat
[cjb47@comp-sc-0120 images]$ singularity run --app fortune ./multiapps-aci.simg -a
** NOTE: Singularity is in a testing phase on ACI-b and is currently unsupported.
FORTUNE PROVIDES QUESTIONS FOR THE GREAT ANSWERS: #19
A: To be or not to be.
Q: What is the square root of 4b^2?
[cjb47@comp-sc-0120 images]$ echo "Hello from lolcat" &gt; file
[cjb47@comp-sc-0120 images]$ singularity run --app lolcat ./multiapps-aci.simg file
** NOTE: Singularity is in a testing phase on ACI-b and is currently unsupported.
Hello from lolcat
</pre>
<p><em>Working with Files:</em></p>
<p>As long as there are corresponding binding points, you will be able to reach files on the host from within the container. Since Roar has user storage in non-standard locations (compared to distribution default), you will need to add the appropriate locations to a recipe.</p>
<p>In the following example, we need binding for ACI-b:</p>
<pre class="script">%post
#ACI mappings so you can access your files.
mkdir -p /storage/home
mkdir -p /storage/work
mkdir -p /gpfs/group
mkdir -p /gpfs/scratch
mkdir -p /var/spool/torque
</pre>
<h5>9.3.7.6 More information on building Singularity containers</h5>
<p>The official <a href="https://www.sylabs.io/guides/2.6/user-guide/">Singularity user guide</a> has additional information and examples related to building and using Singularity containers.</p>
<p>Following are several other use cases:</p>
<ul>
<li>Building containers with GUI support</li>
<li>Building an image with MPI support</li>
<li>Images with GPU support</li>
<li>Running Services</li>
<li>Using sandbox and writable images</li>
</ul>
<p><em>Building Containers with GUI Support</em></p>
<p>A Singularity container can contain a GUI system so that the user can run a GUI application that may not easily be installed on Roar. Here is a simple example of a recipe that has a GUI available:</p>
<pre class="script">Bootstrap: docker
From: centos:centos7
%post
yum -y upgrade
yum -y groupinstall "X Window System"
rpm --import https://packages.microsoft.com/keys/microsoft.asc
echo -e "[code]\nname=Visual Studio Code\nbaseurl=https://packages.microsoft.com/
˓→yumrepos/vscode\nenabled=1\ngpgcheck=1\ngpgkey=https://packages.microsoft.com/keys/
˓→microsoft.asc" &gt; /etc/yum.repos.d/vscode.repo
yum install -y nano emacs vim gedit kate nedit kwrite jed code
yum -y install which xorg-x11-fonts-Type1 liberation-sans-fonts
yum -y install https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm
yum -y install geany geany-plugins*
mkdir -p /storage/home
mkdir -p /storage/work
mkdir -p /gpfs/group
mkdir -p /gpfs/scratch
mkdir -p /var/spool/torque
mkdir -p /run/user/1000/dconf
touch /run/user/1000/dconf/user
%runscript
</pre>
<p>Here is a screenshot of an editor running within that container on an ACI-b compute node:</p>
<p><img loading="lazy" class="alignnone size-large wp-image-7039" src="https://www.icds.psu.edu/wp-content/uploads/2018/11/UsingSingularityonACI-screenshot-1024x999.jpg" alt="" width="1024" height="999" srcset="https://www.icds.psu.edu/wp-content/uploads/2018/11/UsingSingularityonACI-screenshot-1024x999.jpg 1024w, https://www.icds.psu.edu/wp-content/uploads/2018/11/UsingSingularityonACI-screenshot-300x293.jpg 300w, https://www.icds.psu.edu/wp-content/uploads/2018/11/UsingSingularityonACI-screenshot-768x749.jpg 768w, https://www.icds.psu.edu/wp-content/uploads/2018/11/UsingSingularityonACI-screenshot.jpg 1391w" sizes="(max-width: 1024px) 100vw, 1024px" /></p>
<p><em>Building an Image with MPI Support</em></p>
<p>Many HPC applications require the use of MPI. Singularity supports this; however, there are requirements for this:</p>
<ul>
<li>Install InfiniBand libraries in the container</li>
<li>Make the MPI version available to the container, which may be accomplished by setting a bind path to the MPI location</li>
<li>The application must be linked the proper version of MPI</li>
</ul>
<p>Here is an example of the MPI build file:</p>
<pre class="script">BootStrap: yum
OSVersion: 7
MirrorURL: http://mirror.centos.org/centos-%{OSVERSION}/%{OSVERSION}/os/$basearch/
Include: yum
%setup
cd $SINGULARITY_ROOTFS/opt
wget http://www.mpich.org/static/downloads/3.2/mpich-3.2.tar.gz
wget http://lammps.sandia.gov/tars/lammps-stable.tar.gz
%post
yum -y groupinstall "Development Tools"
mkdir -p /opt/mpich
cd /opt/mpich
tar xf ../mpich-3.2.tar.gz --strip-components 1
./configure --prefix=/usr/local |&amp; tee log.configure
make -j |&amp; tee log.make
make install |&amp; tee log.make_install
mkdir -p /opt/lammps
cd /opt/lammps
tar xf ../lammps-stable.tar.gz --strip-components 1
cd src
make yes-granular |&amp; tee log.make_yes_granular
make -j mpi |&amp; tee log.make_mpi
#ACI mappings so you can access your files.
mkdir -p /storage/home
mkdir -p /storage/work
mkdir -p /gpfs/group
mkdir -p /gpfs/scratch
mkdir -p /var/spool/torque
%runscript
/opt/lammps/src/lmp_mpi "$@"
</pre>
<p>Here is an example of an MPI run:</p>
<pre class="script">[cjb47@comp-sc-0174 images]$ module load gcc/5.3.1 mpich/3.2
[cjb47@comp-sc-0174 images]$ mpirun --hostfile $PBS_NODEFILE -np 8 singularity run ./
˓→lammps_mpi.simg  in.friction
** NOTE: Singularity is in a testing phase on ACI-b and is currently unsupported.
** NOTE: Singularity is in a testing phase on ACI-b and is currently unsupported.
** NOTE: Singularity is in a testing phase on ACI-b and is currently unsupported.
** NOTE: Singularity is in a testing phase on ACI-b and is currently unsupported.
** NOTE: Singularity is in a testing phase on ACI-b and is currently unsupported.
** NOTE: Singularity is in a testing phase on ACI-b and is currently unsupported.
** NOTE: Singularity is in a testing phase on ACI-b and is currently unsupported.
** NOTE: Singularity is in a testing phase on ACI-b and is currently unsupported.
LAMMPS (22 Aug 2018)
Lattice spacing in x,y,z = 1.1327 1.96189 1.1327
Created orthogonal box = (0 0 -0.283174) to (56.6348 43.1615 0.283174)
4 by 2 by 1 MPI processor grid
Created 750 atoms
Time spent = 0.00195265 secs
Created 750 atoms
Time spent = 0.00053978 secs
Created 112 atoms
Time spent = 0.000246286 secs
Created 112 atoms
Time spent = 0.0002985 secs
750 atoms in group lo
862 atoms in group lo
750 atoms in group hi
862 atoms in group hi
150 atoms in group lo-fixed
150 atoms in group hi-fixed
300 atoms in group boundary
1424 atoms in group mobile
Setting atom values ...
150 settings made for type
Setting atom values ...
150 settings made for type
WARNING: Temperature for thermo pressure is not for group all (../thermo.cpp:488)
Neighbor list info ...
update every 1 steps, delay 5 steps, check yes
max neighbors/atom: 2000, page size: 100000
master list distance cutoff = 2.8
ghost atom cutoff = 2.8
binsize = 1.4, bins = 41 31 1
1 neighbor lists, perpetual/occasional/extra = 1 0 0
(1) pair lj/cut, perpetual
attributes: half, newton on
pair build: half/bin/atomonly/newton
stencil: half/bin/2d/newton
bin: standard
Setting up Verlet run ...
Unit style : lj
Current step : 0
Time step : 0.0025
Per MPI rank memory allocation (min/avg/max) = 3.048 | 3.049 | 3.049 Mbytes
Step Temp E_pair E_mol TotEng Press Volume
0 0.1 -3.1333672 0 -3.0920969 -1.1437663 2444.9333
1000 0.1 -3.0917089 0 -3.0504386 -0.023690937 2444.9333
2000 0.082122114 -3.0852042 0 -3.0513121 -0.43261548 2444.9333
3000 0.081076017 -3.0813279 0 -3.0478675 -0.34285337 2444.9333
4000 0.094734274 -3.0722764 0 -3.0331792 -0.31676394 2444.9333
5000 0.11433917 -3.0594274 0 -3.0122393 -0.14791034 2444.9333
6000 0.11055427 -3.046338 0 -3.0007119 -0.22376263 2444.9333
7000 0.1 -3.045677 0 -3.0044067 -0.42807494 2444.9333
8000 0.11471279 -3.0383911 0 -2.9910488 -0.30901046 2444.9333
9000 0.11181441 -3.037818 0 -2.9916719 -0.41346773 2444.9333
10000 0.10709722 -3.0390765 0 -2.9948772 -0.27785942 2444.9333
11000 0.1 -3.0404147 0 -2.9991444 -0.50482354 2444.9333
12000 0.11767118 -3.0483134 0 -2.9997502 -0.12862642 2444.9333
13000 0.11773859 -3.0569926 0 -3.0084016 -0.36892682 2444.9333
14000 0.11272521 -3.0514207 0 -3.0048987 -0.36445405 2444.9333
15000 0.10522749 -3.0506428 0 -3.0072151 -0.35624388 2444.9333
16000 0.11015277 -3.0509982 0 -3.0055378 -0.19177436 2444.9333
17000 0.1081148 -3.0478773 0 -3.003258 -0.3475267 2444.9333
18000 0.11109139 -3.0476586 0 -3.0018109 -0.33148148 2444.9333
19000 0.10911522 -3.0523013 0 -3.0072692 -0.25645655 2444.9333
20000 0.11656944 -3.0534574 0 -3.0053488 -0.33684091 2444.9333
Loop time of 6.56253 on 8 procs for 20000 steps with 1724 atoms
Performance: 658283.185 tau/day, 3047.607 timesteps/s
74.8% CPU use with 8 MPI tasks x no OpenMP threads
MPI task timing breakdown:
Section | min time | avg time | max time |%varavg| %total
---------------------------------------------------------------
Pair | 0.4896 | 0.57526 | 0.75825 | 10.7 | 8.77
Neigh | 0.029521 | 0.03774 | 0.052896 | 4.3 | 0.58
Comm | 3.6847 | 4.1707 | 5.064 | 25.3 | 63.55
Output | 0.0028827 | 0.0031309 | 0.0033143 | 0.3 | 0.05
Modify | 0.076676 | 0.083922 | 0.09419 | 1.8 | 1.28
Other | | 1.692 | | | 25.78
Nlocal: 215.5 ave 286 max 189 min
Histogram: 5 1 0 0 0 0 0 0 1 1
Nghost: 97.875 ave 131 max 77 min
Histogram: 2 1 1 1 1 0 0 0 1 1
Neighs: 1802 ave 2442 max 1569 min
Histogram: 5 1 0 0 0 0 0 0 1 1
Total # of neighbors = 14416
Ave neighs/atom = 8.36195
Neighbor list builds = 720
Dangerous builds = 0
Total wall time: 0:00:06
</pre>
<p><em>Images with GPU Support</em></p>
<p>You can build a Singularity image with GPU support or find a pre-built one. You will need to make sure the version of CUDA that is to be used (i.e., the version of the CUDA that will be in the environment, check GPU documentation for more information) matches that of the image you plan to use. The <a href="http://singularity.lbl.gov/docs-instances">Official Singularity User Guide</a> has more details.</p>
<p>Note that many services require sudo access and thus cannot be run on Roar.</p>
<p><em>Running Services</em></p>
<p>In some cases, a piece of software, such as database or web server, is meant to be run in the background and accessed as a server. In some cases, it is possible to run these as an instance.</p>
<p><em>Using Sandbox and Writable Images</em></p>
<p>Recipes are the most reproducible method of preparing images, but you can use writable and sandbox images to build the image interactively. By default, all Singularity images are temporary, which means changes are not retained when the image is stopped (i.e., when<br />
the shell is exited, the command has completed running, or the instance is stopped by the <code>instance.stop</code> command).</p>




	<a name="10-00-policies"></a><br>
	<h3>10 Policies</h3>
	<p class="noindent">By requesting a Roar user account, users acknowledge that they have read and understood all Roar and applicable Pennsylvania State University policies and agree to abide by said policies. All policies can be found at our <a href="https://www.icds.psu.edu/computing-services/icds-aci-policies/">policies page</a>.<br />
<!--l. 1467--></p>




	<a name="10-01-authentication-access-control"></a><br>
	<h4>10.1 Authentication and Access Control</h4>
	<p><!--l. 1469--></p>
<p class="noindent">This policy serves to manage the lifecycle of accounts created under the current state and configuration of Roar. It specifies criteria for creating a user account, using an account, and termination of a user account.</p>
<p><!--l. 1471--></p>




	<a name="10-02-data-protection-retention"></a><br>
	<h4>10.2 Data Protection and Retention</h4>
	<p><!--l. 1473--></p>
<p class="noindent">This policy outlines the protection of data that is created, collected or manipulated by personnel that fall within the scope of Roar and applies to any person who uses Roar resources or handles data managed by Roar. It specifies data retention policies and resources, as well as the responsibilities of the principal investigator, the University, and Roar.<br />
<!--l. 1475--></p>




	<a name="10-03-software-acceptable-use"></a><br>
	<h4>10.3 Software Acceptable Use</h4>
	<p><!--l. 1477--></p>
<p class="noindent">This policy explains how software is introduced, installed, and maintained on the Roar computer system. The policy details how users can install their own software in their user or group spaces, as well as how ICDS will regularly update the Roar software stack. Information on how to request new software for the Roar software stack is included. The policy also discusses who is responsible for licensing and usage agreements in various circumstances, and the rights that ICDS reserves to make changes to installed software in order to keep Roar systems safe, up-to-date, and in compliance with University and government regulations.<br />
<!--l. 1479--></p>




	<a name="10-04-sla-terms-conditions"></a><br>
	<h4>10.4 SLA Terms and Conditions</h4>
	<p><!--l. 1481--></p>
<p class="noindent">This terms and conditions document outlines the basic provisions that guide the working relationships between researchers and Roar.</p>




	<a name="11-00-for-further-assistance"></a><br>
	<h3>11 For Further Assistance</h3>
	<p class="noindent">The <a class="url" href="https://iask.aci.ics.psu.edu">i-ASK Center</a> provides prompt, expert assistance for any issues researchers might encounter on Roar and is the point of contact for the ICDS technical staff. This help desk web portal lets you submit and track tickets and features a helpful list of FAQs. The i-ASK Center also provides timely system alerts regarding maintenance and other events that impact the system.</p>




    </div>
    <!-- end .column padding-lr three-quarters -->
    <div class="column quarter sub-navigation">
    <nav class="accord">
		<h3>Table of Contents</h3>
		<ul>
		 <li class="page_item page-item-12753"><a href="#0-were-redesigning-the-roar-user-guide">0 We&#8217;re Redesigning the Roar User Guide!</a></li>
<li class="page_item page-item-743 page_item_has_children dropdown"><a href="#01-00-introduction">1 Introduction</a>
<ul class='dropdown-menu children'>
	<li class="page_item page-item-1254"><a href="#01-01-icds-aci">1.1 What is Roar?</a></li>
	<li class="page_item page-item-1281"><a href="#01-02-icds-aci">1.2 What does Roar do?</a></li>
	<li class="page_item page-item-1283"><a href="#01-03-mission">1.3 Our Mission</a></li>
	<li class="page_item page-item-1286"><a href="#01-04-vision">1.4 Our Vision</a></li>
</ul>
</li>
<li class="page_item page-item-745"><a href="#02-00-ics-aci-history">2 Roar History</a></li>
<li class="page_item page-item-747 page_item_has_children dropdown"><a href="#03-00-system-overview">3 System Overview</a>
<ul class='dropdown-menu children'>
	<li class="page_item page-item-2097"><a href="#03-01-aci-b">3.1 ACI-b</a></li>
	<li class="page_item page-item-2106"><a href="#03-02-aci">3.2 ACI-I</a></li>
	<li class="page_item page-item-2109"><a href="#03-03-aci-open-queue">3.3 Roar Open Queue</a></li>
	<li class="page_item page-item-8087"><a href="#03-04-hprc">3.4 HPRC</a></li>
	<li class="page_item page-item-2112"><a href="#03-05-filesystems">3.5 Filesystems</a></li>
	<li class="page_item page-item-2115"><a href="#03-06-data-manager">3.6 Data Manager</a></li>
</ul>
</li>
<li class="page_item page-item-749 page_item_has_children dropdown"><a href="#04-00-system-access">4 System Access</a>
<ul class='dropdown-menu children'>
	<li class="page_item page-item-2118"><a href="#04-01-sponsorship">4.1 Sponsorship</a></li>
	<li class="page_item page-item-2121"><a href="#04-02-permissions-use-resources">4.2 Permissions to use Resources</a></li>
	<li class="page_item page-item-2125"><a href="#04-03-getting-account">4.3 Getting an Account</a></li>
</ul>
</li>
<li class="page_item page-item-2131 page_item_has_children dropdown"><a href="#05-00-basics-aci-resources">5 Basics of the Roar Resources</a>
<ul class='dropdown-menu children'>
	<li class="page_item page-item-751"><a href="#05-01-system-usage">5.1 System Usage</a></li>
	<li class="page_item page-item-2134"><a href="#05-02-module-system">5.2 Module System</a></li>
	<li class="page_item page-item-2137"><a href="#05-03-connecting-aci-b">5.3 Connecting to ACI-b</a></li>
	<li class="page_item page-item-2140 page_item_has_children dropdown"><a href="#05-04-connecting-aci">5.4 Connecting to ACI-i</a>
	<ul class='dropdown-menu children'>
		<li class="page_item page-item-8458"><a href="#05-041-open-ondemand">5.4.1 Open OnDemand</a></li>
	</ul>
</li>
	<li class="page_item page-item-8092"><a href="#05-05-connecting-to-hprc">5.5 Connecting to HPRC</a></li>
	<li class="page_item page-item-2143"><a href="#05-06-transferring-data-aci">5.6 Transferring Data to and from Roar</a></li>
</ul>
</li>
<li class="page_item page-item-753 page_item_has_children dropdown"><a href="#06-00-application-development">6 Application Development</a>
<ul class='dropdown-menu children'>
	<li class="page_item page-item-6209"><a href="#06-01-version-control">6.1 Version Control</a></li>
	<li class="page_item page-item-6206"><a href="#06-02-basic-compilation">6.2 Basic Compilation</a></li>
	<li class="page_item page-item-2146"><a href="#06-03-libraries">6.3 Libraries</a></li>
</ul>
</li>
<li class="page_item page-item-755 page_item_has_children dropdown"><a href="#07-00-running-jobs-on-aci-b">7 Running Jobs on ACI-b</a>
<ul class='dropdown-menu children'>
	<li class="page_item page-item-2150"><a href="#07-01-requesting-resources">7.1 Requesting Resources</a></li>
	<li class="page_item page-item-2153"><a href="#07-02-interactive-compute-sessions-aci-b">7.2 Interactive Compute Sessions on ACI-b</a></li>
	<li class="page_item page-item-2156"><a href="#07-03-pbs-environmental-variables">7.3 PBS Environmental Variables</a></li>
	<li class="page_item page-item-2158"><a href="#07-04-great-allocations">7.4 GReaT Allocations</a></li>
	<li class="page_item page-item-7013"><a href="#07-05-aci-b-gpu-nodes">7.5 ACI-b GPU nodes</a></li>
</ul>
</li>
<li class="page_item page-item-8098 page_item_has_children dropdown"><a href="#08-00-running-jobs-on-hprc">8 Running Jobs on HPRC</a>
<ul class='dropdown-menu children'>
	<li class="page_item page-item-8100 page_item_has_children dropdown"><a href="#08-01-requesting-resources">8.1 Requesting Resources</a>
	<ul class='dropdown-menu children'>
		<li class="page_item page-item-8102"><a href="#08-012-sample-script">8.1.1 Sample HPRC Batch Submission Script</a></li>
	</ul>
</li>
	<li class="page_item page-item-8105"><a href="#08-02-interactive-compute-sessions-on-hprc">8.2 Interactive Compute Sessions on HPRC</a></li>
	<li class="page_item page-item-8107"><a href="#08-03-requesting-a-custom-singularity-container-on-hprc">8.3 Requesting a Custom Singularity Container on HPRC</a></li>
	<li class="page_item page-item-8109"><a href="#08-04-specifying-a-custom-bash-environment-on-hprc">8.4 Specifying a Custom Bash Environment on HPRC</a></li>
</ul>
</li>
<li class="page_item page-item-758 page_item_has_children dropdown"><a href="#09-00-software-stack">9 Software Stack</a>
<ul class='dropdown-menu children'>
	<li class="page_item page-item-2161"><a href="#09-01-user-stack">9.1 User Stack</a></li>
	<li class="page_item page-item-2164"><a href="#09-02-system-stack">9.2 System Stack</a></li>
	<li class="page_item page-item-2167"><a href="#09-03-system-stack-applications">9.3 System Stack Applications</a></li>
</ul>
</li>
<li class="page_item page-item-760 page_item_has_children dropdown"><a href="#10-00-policies">10 Policies</a>
<ul class='dropdown-menu children'>
	<li class="page_item page-item-2170"><a href="#10-01-authentication-access-control">10.1 Authentication and Access Control</a></li>
	<li class="page_item page-item-2173"><a href="#10-02-data-protection-retention">10.2 Data Protection and Retention</a></li>
	<li class="page_item page-item-2176"><a href="#10-03-software-acceptable-use">10.3 Software Acceptable Use</a></li>
	<li class="page_item page-item-2179"><a href="#10-04-sla-terms-conditions">10.4 SLA Terms and Conditions</a></li>
</ul>
</li>
<li class="page_item page-item-762"><a href="#11-00-for-further-assistance">11 For Further Assistance</a></li>
		</ul>
		<p class="jump-to-top"><a href="#jump-top">Back to Top ▲</a></p>
		</nav>
		<div class="accord">
  
		</div><!-- end .accord -->
    </div>
    <!-- end .column quarter sub-navigation --> 
    
  </div>
  <!-- end .container align-flex-s.container-article -->
</div>
<!-- end #main -->

<!-- / CONTENT -->

<script type="text/javascript">
	jQuery(document).ready(function ($) {
		// Add 'expand' class to 'li' tags having 'ul' tag inside them and initially hiding content 
		$('.accord ul li:has(ul)').addClass('expand').find('ul').hide();
		// Add '<span>[ + ]</span>' after anchor inside 'li' tags those have 'expand' class
		$('.accord ul li.expand>a').after('<span style="white-space: nowrap">[ + ]</span>');
		
		// Change [ - ] with [ + ] and  'collapse' class with 'expand' and sliding content upward
		$('.accord ul').on('click', 'li.collapse span ', function (e) {
			$(this).text('[ + ]').parent().addClass('expand').removeClass('collapse').find('>ul').slideUp();
			e.stopImmediatePropagation();
		});

		// Change [ + ] with [ - ] and 'expand' class with 'collapse' class and sliding content downward
		$('.accord ul').on('click', 'li.expand span', function (e) {
			$(this).text('[ - ]').parent().addClass('collapse').removeClass('expand').find('>ul').slideDown();
			e.stopImmediatePropagation();
		});
		
		// Preventing rest of handlers from being execute
		$('.accord ul').on('click', 'li.collapse li:not(.collapse)', function (e) {
			e.stopImmediatePropagation();
		});		
	});
</script>
 <footer>
  <div class="container max-width divider flex-centered padding-lr">
      <img src="https://www.icds.psu.edu/wp-content/themes/ics/assets/images/icds-clover-dark-bg-small.png" class="actual-size" alt="">
  </div>
  <div class="container fit-columns max-width padding-lr flex-centered">
    <div class="column padding-lr">
        <a href="/">
            <img src="https://www.icds.psu.edu/wp-content/themes/ics/assets/images/PSU_logo_white.png" alt="Penn State Institute for Computational and Data Sciences Logo">
        </a>
      <p class="address">224B Computer Building<br />
        <a href="mailto:icds@psu.edu">icds@psu.edu</a><br />
        814-867-1467</p>
    </div>
    <div class="column padding-lr">
      <p class="footer-section">About</p>
      <ul>
        <li id="menu-item-243" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-243"><a href="https://www.icds.psu.edu/about/">Overview</a></li>
<li id="menu-item-244" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-244"><a href="https://www.icds.psu.edu/about/meet-the-icds-team/icds-staff/">Staff</a></li>
<li id="menu-item-99" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-99"><a href="https://www.icds.psu.edu/careers/">Careers</a></li>
<li id="menu-item-109" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-109"><a href="https://www.icds.psu.edu/sitemap/">Sitemap</a></li>
      </ul>
    </div>
    <div class="column padding-lr">
      <p class="footer-section">i-ASK Support Center</p>
      <ul>
        <li id="menu-item-434" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-434"><a href="https://www.icds.psu.edu/computing-services/account-setup/">Account Set-Up</a></li>
<li id="menu-item-5511" class="menu-item menu-item-type-post_type menu-item-object-page current-menu-item page_item page-item-400 current_page_item menu-item-5511"><a href="https://www.icds.psu.edu/computing-services/roar-user-guide/" aria-current="page">Roar Supercomputer User Guide</a></li>
<li id="menu-item-433" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-433"><a href="https://www.icds.psu.edu/computing-services/support/">i-ASK Help Center</a></li>
        <li>814-865-4275</li>
      </ul>
    </div>
    <div class="column padding-lr">
      <p class="footer-section">Sign Up for ICDS Announcements</p>
		<ul><li><a href="/subscribe" style="display: inline">Subscribe to Our Mailing List</a></li></ul> 
      <!--<form class="flex-on-one-line" method="post" action="">
        <label for="email" class="header-label">Search</label>
        <input id="" name="email" id="email" type="email" placeholder="Email Address" maxlength="200" value="">
        <button name="submit" class="btn" type="submit" value="Go">Submit</button>
      </form>-->
      <p class="footer-section">Follow Us</p>
      <ul class="social-icons-lists icons-background-rounded">

			
				<li class="social-icons-list-item">
					<a href="https://twitter.com/icds_psu" target="_blank"  class="social-icon">
						<span class="socicon socicon-twitter" style="padding: 10px; font-size: 14px; background-color: #4da7de"></span>

											</a>
				</li>

			
				<li class="social-icons-list-item">
					<a href="https://www.youtube.com/channel/UCnPq-88xAN4YeMbfD5_7Crg" target="_blank"  class="social-icon">
						<span class="socicon socicon-youtube" style="padding: 10px; font-size: 14px; background-color: #e02a20"></span>

											</a>
				</li>

			
				<li class="social-icons-list-item">
					<a href="https://www.facebook.com/PennStateICDS/" target="_blank"  class="social-icon">
						<span class="socicon socicon-facebook" style="padding: 10px; font-size: 14px; background-color: #3e5b98"></span>

											</a>
				</li>

			
				<li class="social-icons-list-item">
					<a href="https://www.linkedin.com/company/penn-state-institute-for-computational-and-data-sciences" target="_blank"  class="social-icon">
						<span class="socicon socicon-linkedin" style="padding: 10px; font-size: 14px; background-color: #3371b7"></span>

											</a>
				</li>

			
		</ul>    </div>
  </div>
  <div class="container max-width padding-lr">
    <div class="column full text-center">
      <p class="tagline">ICDS helps you apply big data and big simulation methods across the research landscape.</p>
      <p class="copyright">&copy;2021 <a title="Penn State home page." href="http://www.psu.edu/">Penn State.</a> All rights reserved. <a href="http://www.psu.edu/ur/legal.html">Privacy and Legal Statements</a> </p>
    </div>
  </div>
</footer>
<script src="https://www.icds.psu.edu/wp-content/themes/ics/assets/js/cbpHorizontalMenu.js"></script>
<script type='text/javascript' src='https://www.icds.psu.edu/wp-content/plugins/accordion-blocks/js/accordion-blocks.min.js?ver=1.4.1' id='pb-accordion-blocks-frontend-script-js'></script>
<script type='text/javascript' src='https://www.icds.psu.edu/wp-includes/js/dist/vendor/regenerator-runtime.min.js?ver=0.13.7' id='regenerator-runtime-js'></script>
<script type='text/javascript' src='https://www.icds.psu.edu/wp-includes/js/dist/vendor/wp-polyfill.min.js?ver=3.15.0' id='wp-polyfill-js'></script>
<script type='text/javascript' id='contact-form-7-js-extra'>
/* <![CDATA[ */
var wpcf7 = {"api":{"root":"https:\/\/www.icds.psu.edu\/wp-json\/","namespace":"contact-form-7\/v1"}};
/* ]]> */
</script>
<script type='text/javascript' src='https://www.icds.psu.edu/wp-content/plugins/contact-form-7/includes/js/index.js?ver=5.5.3' id='contact-form-7-js'></script>
<script type='text/javascript' id='wpcf7cf-scripts-js-extra'>
/* <![CDATA[ */
var wpcf7cf_global_settings = {"ajaxurl":"https:\/\/www.icds.psu.edu\/wp-admin\/admin-ajax.php"};
/* ]]> */
</script>
<script type='text/javascript' src='https://www.icds.psu.edu/wp-content/plugins/cf7-conditional-fields/js/scripts.js?ver=2.0.8' id='wpcf7cf-scripts-js'></script>
<script type='text/javascript' src='https://www.google.com/recaptcha/api.js?render=6Lfr_KUZAAAAAJq2B8yFUBkHMrVu9aiM371QP4d7&#038;ver=3.0' id='google-recaptcha-js'></script>
<script type='text/javascript' id='wpcf7-recaptcha-js-extra'>
/* <![CDATA[ */
var wpcf7_recaptcha = {"sitekey":"6Lfr_KUZAAAAAJq2B8yFUBkHMrVu9aiM371QP4d7","actions":{"homepage":"homepage","contactform":"contactform"}};
/* ]]> */
</script>
<script type='text/javascript' src='https://www.icds.psu.edu/wp-content/plugins/contact-form-7/modules/recaptcha/index.js?ver=5.5.3' id='wpcf7-recaptcha-js'></script>
<script type='text/javascript' src='https://www.icds.psu.edu/wp-includes/js/wp-embed.min.js?ver=5.8.2' id='wp-embed-js'></script>
<script type='text/javascript' src='https://www.icds.psu.edu/wp-content/plugins/tablepress/js/jquery.datatables.min.js?ver=1.14' id='tablepress-datatables-js'></script>
<script type="text/javascript">
jQuery(function($){
$('#tablepress-30').dataTable({"stripeClasses":["even","odd"],"ordering":false,"paging":false,"searching":false,"info":false});
});
</script></body>
</html>



